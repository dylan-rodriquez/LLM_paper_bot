# SoK: Are Watermarks in LLMs Ready for Deployment?

**Authors:** Kieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah, My Thai

**Published:** 2025-06-09 | **Source:** arXiv RSS

**Categories:** cs.CR

**Significance Score:** 92.0/100

## Abstract

arXiv:2506.05594v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.
  To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.

## Analysis

**Innovation Score:** 70.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 80.0/100

**Justification:** This paper tackles a highly relevant and timely problem â€“ the security and intellectual property protection of LLMs. The 'Systematization of Knowledge' (SoK) approach, including a taxonomy and a novel classifier, suggests a rigorous and well-structured investigation. While the abstract doesn't detail the specifics of the classifier, the overall framing indicates a strong potential for impact and positive reception within the LLM security community.

## Keywords

llms, watermarks, watermarks llms, deployment, models, potential, attack, community, deploying, impacts

## Links

- [Paper URL](https://arxiv.org/abs/2506.05594)

---
*Auto-generated on 2025-06-09 09:30:26 UTC*
