# SNS-Bench-VL: Benchmarking Multimodal Large Language Models in Social Networking Services

**Authors:** Hongcheng Guo, Zheyong Xie, Shaosheng Cao, Boyang Wang, Weiting Liu, Anjie Le, Lei Li, Zhoujun Li

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 35.3/100

## Abstract

arXiv:2505.23065v1 Announce Type: new 
Abstract: With the increasing integration of visual and textual content in Social Networking Services (SNS), evaluating the multimodal capabilities of Large Language Models (LLMs) is crucial for enhancing user experience, content understanding, and platform intelligence. Existing benchmarks primarily focus on text-centric tasks, lacking coverage of the multimodal contexts prevalent in modern SNS ecosystems. In this paper, we introduce SNS-Bench-VL, a comprehensive multimodal benchmark designed to assess the performance of Vision-Language LLMs in real-world social media scenarios. SNS-Bench-VL incorporates images and text across 8 multimodal tasks, including note comprehension, user engagement analysis, information retrieval, and personalized recommendation. It comprises 4,001 carefully curated multimodal question-answer pairs, covering single-choice, multiple-choice, and open-ended tasks. We evaluate over 25 state-of-the-art multimodal LLMs, analyzing their performance across tasks. Our findings highlight persistent challenges in multimodal social context comprehension. We hope SNS-Bench-VL will inspire future research towards robust, context-aware, and human-aligned multimodal intelligence for next-generation social networking services.

## Analysis

**Innovation Score:** 20.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 57.5/100

**Justification:** Contains key LLM terms (bonus: 10)

## Keywords

multimodal, sns, social, bench, bench vl, sns bench, tasks, vl, language, llms

## Links

- [Paper URL](https://arxiv.org/abs/2505.23065)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
