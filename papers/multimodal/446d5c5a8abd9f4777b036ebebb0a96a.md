# Multimodal Large Language Models: A Survey

**Authors:** Longzhen Han, Awes Mubarak, Almas Baimagambetov, Nikolaos Polatidis, Thar Baker

**Published:** 2025-06-13 | **Source:** arXiv RSS

**Categories:** cs.MM

**Significance Score:** 92.0/100

## Abstract

arXiv:2506.10016v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have rapidly evolved beyond text generation, now spanning diverse output modalities including images, music, video, human motion, and 3D objects, by integrating language with other sensory modalities under unified architectures. This survey categorises six primary generative modalities and examines how foundational techniques, namely Self-Supervised Learning (SSL), Mixture of Experts (MoE), Reinforcement Learning from Human Feedback (RLHF), and Chain-of-Thought (CoT) prompting, enable cross-modal capabilities. We analyze key models, architectural trends, and emergent cross-modal synergies, while highlighting transferable techniques and unresolved challenges. Architectural innovations like transformers and diffusion models underpin this convergence, enabling cross-modal transfer and modular specialization. We highlight emerging patterns of synergy, and identify open challenges in evaluation, modularity, and structured reasoning. This survey offers a unified perspective on MLLM development and identifies critical paths toward more general-purpose, adaptive, and interpretable multimodal systems.

## Analysis

**Innovation Score:** 65.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 90.0/100

**Justification:** This survey paper addresses a highly relevant and rapidly evolving field â€“ Multimodal Large Language Models. The categorization of generative modalities and analysis of foundational techniques (SSL, MoE, RLHF, CoT) provides a valuable overview for researchers. While the abstract doesn't detail novel *methods*, the comprehensive scope and synthesis of existing work suggest high quality and potential impact, and the field is currently experiencing significant interest.

## Keywords

cross, models, cross modal, language, modal, modalities, multimodal, survey, architectural, challenges

## Links

- [Paper URL](https://arxiv.org/abs/2506.10016)

---
*Auto-generated on 2025-06-13 09:29:22 UTC*
