# NegVQA: Can Vision Language Models Understand Negation?

**Authors:** Yuhui Zhang, Yuchang Su, Yiming Liu, Serena Yeung-Levy

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 35.4/100

## Abstract

arXiv:2505.22946v1 Announce Type: new 
Abstract: Negation is a fundamental linguistic phenomenon that can entirely reverse the meaning of a sentence. As vision language models (VLMs) continue to advance and are deployed in high-stakes applications, assessing their ability to comprehend negation becomes essential. To address this, we introduce NegVQA, a visual question answering (VQA) benchmark consisting of 7,379 two-choice questions covering diverse negation scenarios and image-question distributions. We construct NegVQA by leveraging large language models to generate negated versions of questions from existing VQA datasets. Evaluating 20 state-of-the-art VLMs across seven model families, we find that these models struggle significantly with negation, exhibiting a substantial performance drop compared to their responses to the original questions. Furthermore, we uncover a U-shaped scaling trend, where increasing model size initially degrades performance on NegVQA before leading to improvements. Our benchmark reveals critical gaps in VLMs' negation understanding and offers insights into future VLM development. Project page available at https://yuhui-zh15.github.io/NegVQA/.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 40.0/100  
**Sentiment Score:** 50.6/100

**Justification:** High innovation indicators (score: 30); Strong impact potential (score: 40); Contains key LLM terms (bonus: 5)

## Keywords

negation, negvqa, models, language, language models, questions, vlms, benchmark, model, performance

## Links

- [Paper URL](https://arxiv.org/abs/2505.22946)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
