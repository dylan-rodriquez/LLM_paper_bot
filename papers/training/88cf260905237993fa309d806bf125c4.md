# Detecting Stealthy Backdoor Samples based on Intra-class Distance for Large Language Models

**Authors:** Jinwen Chen, Hainan Zhang, Fei Sun, Qinnan Zhang, Sijia Wen, Ziwei Wang, Zhiming Zheng

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 36.0/100

## Abstract

arXiv:2505.23015v1 Announce Type: new 
Abstract: Fine-tuning LLMs with datasets containing stealthy backdoors from publishers poses security risks to downstream applications. Mainstream detection methods either identify poisoned samples by analyzing the prediction probability of poisoned classification models or rely on the rewriting model to eliminate the stealthy triggers. However, the former cannot be applied to generation tasks, while the latter may degrade generation performance and introduce new triggers. Therefore, efficiently eliminating stealthy poisoned samples for LLMs remains an urgent problem. We observe that after applying TF-IDF clustering to the sample response, there are notable differences in the intra-class distances between clean and poisoned samples. Poisoned samples tend to cluster closely because of their specific malicious outputs, whereas clean samples are more scattered due to their more varied responses. Thus, in this paper, we propose a stealthy backdoor sample detection method based on Reference-Filtration and Tfidf-Clustering mechanisms (RFTC). Specifically, we first compare the sample response with the reference model's outputs and consider the sample suspicious if there's a significant discrepancy. And then we perform TF-IDF clustering on these suspicious samples to identify the true poisoned samples based on the intra-class distance. Experiments on two machine translation datasets and one QA dataset demonstrate that RFTC outperforms baselines in backdoor detection and model performance. Further analysis of different reference models also confirms the effectiveness of our Reference-Filtration.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 46.1/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)

## Keywords

samples, poisoned, poisoned samples, stealthy, reference, sample, backdoor, based, class, clustering

## Links

- [Paper URL](https://arxiv.org/abs/2505.23015)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
