# Calibrated Value-Aware Model Learning with Stochastic Environment Models

**Authors:** Claas Voelcker, Anastasiia Pedan, Arash Ahmadian, Romina Abachi, Igor Gilitschenski, Amir-massoud Farahmand

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.22772v1 Announce Type: new 
Abstract: The idea of value-aware model learning, that models should produce accurate value estimates, has gained prominence in model-based reinforcement learning. The MuZero loss, which penalizes a model's value function prediction compared to the ground-truth value function, has been utilized in several prominent empirical works in the literature. However, theoretical investigation into its strengths and weaknesses is limited. In this paper, we analyze the family of value-aware model learning losses, which includes the popular MuZero loss. We show that these losses, as normally used, are uncalibrated surrogate losses, which means that they do not always recover the correct model and value function. Building on this insight, we propose corrections to solve this issue. Furthermore, we investigate the interplay between the loss calibration, latent model architectures, and auxiliary losses that are commonly employed when training MuZero-style agents. We show that while deterministic models can be sufficient to predict accurate values, learning calibrated stochastic models is still advantageous.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 78.0/100  
**Sentiment Score:** 80.0/100

**Justification:** This paper tackles a crucial theoretical gap in value-aware model learning, specifically regarding the calibration of losses like MuZero. Identifying and correcting uncalibrated surrogate losses is a significant contribution, potentially leading to more robust and reliable model-based RL agents. The investigation into the interplay of loss calibration, architectures, and auxiliary losses suggests a comprehensive approach to improving MuZero-style agents. The work appears rigorous and addresses a relevant problem within the RL community.

## Keywords

model, value, learning, losses, models, aware, aware model, function, loss, model learning

## Links

- [Paper URL](https://arxiv.org/abs/2505.22772)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
