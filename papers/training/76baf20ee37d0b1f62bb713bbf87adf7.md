# The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning

**Authors:** Shiwei Li, Xiandi Luo, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 82.0/100

## Abstract

arXiv:2505.23176v1 Announce Type: new 
Abstract: To improve the training efficiency of federated learning (FL), previous research has employed low-rank decomposition techniques to reduce communication overhead. In this paper, we seek to enhance the performance of these low-rank decomposition methods. Specifically, we focus on three key issues related to decomposition in FL: what to decompose, how to decompose, and how to aggregate. Subsequently, we introduce three novel techniques: Model Update Decomposition (MUD), Block-wise Kronecker Decomposition (BKD), and Aggregation-Aware Decomposition (AAD), each targeting a specific issue. These techniques are complementary and can be applied simultaneously to achieve optimal performance. Additionally, we provide a rigorous theoretical analysis to ensure the convergence of the proposed MUD. Extensive experimental results show that our approach achieves faster convergence and superior accuracy compared to relevant baseline methods. The code is available at https://github.com/Leopold1423/fedmud-icml25.

## Analysis

**Innovation Score:** 70.0/100
**Impact Score:** 75.0/100  
**Sentiment Score:** 85.0/100

**Justification:** The paper addresses a relevant and important problem in federated learning – communication efficiency – by focusing on low-rank decomposition. The proposed three techniques (MUD, BKD, AAD) seem well-motivated and complementary, and the theoretical convergence analysis for MUD is a strong point. While the approach isn't radically new, it appears to offer a systematic and potentially effective improvement over existing methods, as evidenced by the reported experimental results. The high sentiment score reflects the current interest in efficient FL techniques.

## Keywords

decomposition, low, low rank, rank, rank decomposition, techniques, communication, convergence, decompose, federated

## Links

- [Paper URL](https://arxiv.org/abs/2505.23176)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
