# Machine Learning Models Have a Supply Chain Problem

**Authors:** Sarah Meiklejohn, Hayden Blauzvern, Mihai Maruseac, Spencer Schrock, Laurent Simon, Ilia Shumailov

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.22778v1 Announce Type: new 
Abstract: Powerful machine learning (ML) models are now readily available online, which creates exciting possibilities for users who lack the deep technical expertise or substantial computing resources needed to develop them. On the other hand, this type of open ecosystem comes with many risks. In this paper, we argue that the current ecosystem for open ML models contains significant supply-chain risks, some of which have been exploited already in real attacks. These include an attacker replacing a model with something malicious (e.g., malware), or a model being trained using a vulnerable version of a framework or on restricted or poisoned data. We then explore how Sigstore, a solution designed to bring transparency to open-source software supply chains, can be used to bring transparency to open ML models, in terms of enabling model publishers to sign their models and prove properties about the datasets they use.

## Analysis

**Innovation Score:** 65.0/100
**Impact Score:** 80.0/100  
**Sentiment Score:** 82.0/100

**Justification:** This paper addresses a very timely and important problem â€“ the security of the open ML model supply chain. The argument is well-articulated and the proposed exploration of Sigstore as a potential solution is logical. While the core idea of applying supply chain security principles isn't entirely novel, its application to ML models is a valuable contribution, and the potential impact is significant given the increasing reliance on pre-trained models.

## Keywords

models, open, ml, ml models, model, supply, bring, bring transparency, chain, ecosystem

## Links

- [Paper URL](https://arxiv.org/abs/2505.22778)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
