# DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs

**Authors:** Xinyu Yao, Daniel Bourgeois, Abhinav Jain, Yuxin Tang, Jiawen Yao, Zhimin Ding, Arlei Silva, Chris Jermaine

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.23131v1 Announce Type: new 
Abstract: We study the problem of assigning operations in a dataflow graph to devices to minimize execution time in a work-conserving system, with emphasis on complex machine learning workloads. Prior learning-based methods often struggle due to three key limitations: (1) reliance on bulk-synchronous systems like TensorFlow, which under-utilize devices due to barrier synchronization; (2) lack of awareness of the scheduling mechanism of underlying systems when designing learning-based methods; and (3) exclusive dependence on reinforcement learning, ignoring the structure of effective heuristics designed by experts. In this paper, we propose \textsc{Doppler}, a three-stage framework for training dual-policy networks consisting of 1) a $\mathsf{SEL}$ policy for selecting operations and 2) a $\mathsf{PLC}$ policy for placing chosen operations on devices. Our experiments show that \textsc{Doppler} outperforms all baseline methods across tasks by reducing system execution time and additionally demonstrates sampling efficiency by reducing per-episode training time.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 80.0/100  
**Sentiment Score:** 78.0/100

**Justification:** The paper addresses a significant problem in deploying ML workloads efficiently, particularly highlighting the limitations of current systems like TensorFlow. The dual-policy approach, combining selection and placement, and acknowledging existing heuristics is a strong methodological choice. While the abstract doesn't detail the novelty of the policies themselves, the framework appears well-motivated and likely to yield improvements over existing methods. The focus on asynchronous dataflow graphs is particularly relevant given current trends in distributed ML.

## Keywords

learning, policy, devices, doppler, methods, operations, time, based, based methods, dataflow

## Links

- [Paper URL](https://arxiv.org/abs/2505.23131)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
