# Weight Spectra Induced Efficient Model Adaptation

**Authors:** Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 82.0/100

## Abstract

arXiv:2505.23099v1 Announce Type: new 
Abstract: Large-scale foundation models have demonstrated remarkable versatility across a wide range of downstream tasks. However, fully fine-tuning these models incurs prohibitive computational costs, motivating the development of Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA, which introduces low-rank updates to pre-trained weights. Despite their empirical success, the underlying mechanisms by which PEFT modifies model parameters remain underexplored. In this work, we present a systematic investigation into the structural changes of weight matrices during fully fine-tuning. Through singular value decomposition (SVD), we reveal that fine-tuning predominantly amplifies the top singular values while leaving the remainder largely intact, suggesting that task-specific knowledge is injected into a low-dimensional subspace. Furthermore, we find that the dominant singular vectors are reoriented in task-specific directions, whereas the non-dominant subspace remains stable. Building on these insights, we propose a novel method that leverages learnable rescaling of top singular directions, enabling precise modulation of the most influential components without disrupting the global structure. Our approach achieves consistent improvements over strong baselines across multiple tasks, highlighting the efficacy of structurally informed fine-tuning.

## Analysis

**Innovation Score:** 65.0/100
**Impact Score:** 75.0/100  
**Sentiment Score:** 80.0/100

**Justification:** This paper tackles a crucial question in the PEFT landscape â€“ understanding *why* LoRA and similar methods work. The use of SVD to analyze weight changes during fine-tuning is a solid methodological approach. While the finding that fine-tuning amplifies top singular values isn't entirely surprising, the systematic investigation and focus on singular vector reorientation offer valuable insights. The work is well-positioned to be well-received by the community given the current focus on efficient adaptation of large models.

## Keywords

fine, fine tuning, tuning, singular, directions, dominant, efficient, fully, fully fine, low

## Links

- [Paper URL](https://arxiv.org/abs/2505.23099)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
