# GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation

**Authors:** Jiashu He, Mingyu Derek Ma, Jinxuan Fan, Dan Roth, Wei Wang, Alejandro Ribeiro

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.AI

**Significance Score:** 41.9/100

## Abstract

arXiv:2410.08475v3 Announce Type: replace-cross 
Abstract: Existing approaches based on context prompting or reinforcement learning (RL) to improve the reasoning capacities of large language models (LLMs) depend on the LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT). However, no matter the size of LLMs, certain problems cannot be resolved in a single forward pass. Meanwhile, agent-based reasoning systems require access to a comprehensive nonparametric knowledge base, which is often costly or not feasible for use in scientific and niche domains. We present Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning method that merges parametric and non-parametric memories to improve accurate reasoning with minimal external input. GIVE guides the LLM agent to select the most pertinent expert data (observe), engage in query-specific divergent thinking (reflect), and then synthesize this information to produce the final output (speak). Extensive experiments demonstrated the following benefits of our framework: (1) GIVE boosts the performance of LLMs across various sizes. (2) In some scenarios, GIVE allows smaller LLMs to surpass larger, more sophisticated ones in scientific tasks (GPT3.5T + GIVE > GPT4). (3) GIVE is effective on scientific and open-domain assessments. (4) GIVE is a training-free method that enables LLMs to tackle new problems that extend beyond their training data (up to 43.5% -> 88.2%} accuracy improvement). (5) GIVE allows LLM agents to reason using both restricted (very small) and noisy (very large) knowledge sources, accommodating knowledge graphs (KG) ranging from 135 to more than 840k nodes. (6) The reasoning process involved in GIVE is fully interpretable.

## Analysis

**Innovation Score:** 20.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 53.2/100

**Justification:** Contains key LLM terms (bonus: 15)

## Keywords

llms, reasoning, knowledge, large, scientific, agent, allows, based, data, extrapolation

## Links

- [Paper URL](https://arxiv.org/abs/2410.08475)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
