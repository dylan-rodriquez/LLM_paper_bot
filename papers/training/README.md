# Training Papers

This directory contains papers related to training in large language models and AI.

## Papers (82 total)

### Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction

**Score:** 92.0 | **Published:** 2025-05-31 | **Authors:** Dharambir Mahto, Prashant Yadav, Mahesh Banavar, Jim Keany, Alan T Joseph, Srinivas Kilambi

arXiv:2505.22840v1 Announce Type: new 
Abstract: Sepsis is a life-threatening condition affecting over 48.9 million people globally and causing 11 million deaths annually. Despite medical advancements...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22840) | [ğŸ“ Analysis](e6d6095ba63019d55bc8125cbe632089.md)

---

### LUMION: Fast Fault Recovery for ML Jobs Using Programmable Optical Fabrics

**Score:** 88.0 | **Published:** 2025-05-31 | **Authors:** Abhishek Vijaya Kumar, Eric Ding, Arjun Devraj, Darius Bunandar, Rachee Singh

arXiv:2505.23105v1 Announce Type: new 
Abstract: When accelerators fail in modern ML datacenters, operators migrate the affected ML training or inference jobs to entirely new racks. This approach, whi...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23105) | [ğŸ“ Analysis](082f02dc1a229a2308b3d0e1a9220f9a.md)

---

### Private Rate-Constrained Optimization with Applications to Fair Learning

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Mohammad Yaghini, Tudor Cebere, Michael Menart, Aur\'elien Bellet, Nicolas Papernot

arXiv:2505.22703v1 Announce Type: new 
Abstract: Many problems in trustworthy ML can be formulated as minimization of the model error under constraints on the prediction rates of the model for suitabl...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22703) | [ğŸ“ Analysis](07b0122af721c46d2a5d1dd1eedd46d6.md)

---

### Calibrated Value-Aware Model Learning with Stochastic Environment Models

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Claas Voelcker, Anastasiia Pedan, Arash Ahmadian, Romina Abachi, Igor Gilitschenski, Amir-massoud Farahmand

arXiv:2505.22772v1 Announce Type: new 
Abstract: The idea of value-aware model learning, that models should produce accurate value estimates, has gained prominence in model-based reinforcement learnin...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22772) | [ğŸ“ Analysis](30f5f8c3e9cfb28d2a1fba0b560e69a7.md)

---

### Machine Learning Models Have a Supply Chain Problem

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Sarah Meiklejohn, Hayden Blauzvern, Mihai Maruseac, Spencer Schrock, Laurent Simon, Ilia Shumailov

arXiv:2505.22778v1 Announce Type: new 
Abstract: Powerful machine learning (ML) models are now readily available online, which creates exciting possibilities for users who lack the deep technical expe...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22778) | [ğŸ“ Analysis](007cfcaab36bbebd1be0cda65343c855.md)

---

### CLUE: Neural Networks Calibration via Learning Uncertainty-Error alignment

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Pedro Mendes, Paolo Romano, David Garlan

arXiv:2505.22803v1 Announce Type: new 
Abstract: Reliable uncertainty estimation is critical for deploying neural networks (NNs) in real-world applications. While existing calibration techniques often...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22803) | [ğŸ“ Analysis](5445500ec173ca7030e8f1744073838d.md)

---

### How Do Diffusion Models Improve Adversarial Robustness?

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Liu Yuezhang, Xue-Xin Wei

arXiv:2505.22839v1 Announce Type: new 
Abstract: Recent findings suggest that diffusion models significantly enhance empirical adversarial robustness. While some intuitive explanations have been propo...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22839) | [ğŸ“ Analysis](161f2aedac91f3e7e5dfc48b5ee30b0f.md)

---

### Kernel-Smoothed Scores for Denoising Diffusion: A Bias-Variance Study

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Franck Gabriel, Fran\c{c}ois Ged, Maria Han Veiga, Emmanuel Schertzer

arXiv:2505.22841v1 Announce Type: new 
Abstract: Diffusion models now set the benchmark in high-fidelity generative sampling, yet they can, in principle, be prone to memorization. In this case, their ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22841) | [ğŸ“ Analysis](0fed18beaf31ebb880f96e6c8c4261d7.md)

---

### Defining Foundation Models for Computational Science: A Call for Clarity and Rigor

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Youngsoo Choi, Siu Wun Cheung, Youngkyu Kim, Ping-Hsuan Tsai, Alejandro N. Diaz, Ivan Zanardi, Seung Whan Chung, Dylan Matthew Copeland, Coleman Kendrick, William Anderson, Traian Iliescu, Matthias Heinkenschloss

arXiv:2505.22904v1 Announce Type: new 
Abstract: The widespread success of foundation models in natural language processing and computer vision has inspired researchers to extend the concept to scient...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22904) | [ğŸ“ Analysis](fc832d6ea730e6639d9946e85f02e818.md)

---

### Model-Preserving Adaptive Rounding

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Albert Tseng, Zhaofeng Sun, Christopher De Sa

arXiv:2505.22988v1 Announce Type: new 
Abstract: The main goal of post-training quantization (PTQ) is to produced a compressed model whose output distribution is as close to the original model's as po...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22988) | [ğŸ“ Analysis](d0d943c62e1e408133c53c2d97fd47cf.md)

---

### Hybrid Cross-domain Robust Reinforcement Learning

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Linh Le Pham Van, Minh Hoang Nguyen, Hung Le, Hung The Tran, Sunil Gupta

arXiv:2505.23003v1 Announce Type: new 
Abstract: Robust reinforcement learning (RL) aims to learn policies that remain effective despite uncertainties in its environment, which frequently arise in rea...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23003) | [ğŸ“ Analysis](b87dd86c866f1fa9ea67843cc3e88b35.md)

---

### Diverse Prototypical Ensembles Improve Robustness to Subpopulation Shift

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Minh Nguyen Nhat To, Paul F RWilson, Viet Nguyen, Mohamed Harmanani, Michael Cooper, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi, Rahul G. Krishnan

arXiv:2505.23027v1 Announce Type: new 
Abstract: The subpopulationtion shift, characterized by a disparity in subpopulation distributibetween theween the training and target datasets, can significantl...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23027) | [ğŸ“ Analysis](a2396f50d5f1f0a8ef226988821f0418.md)

---

### MAP: Revisiting Weight Decomposition for Low-Rank Adaptation

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Chongjie Si, Zhiyi Shi, Yadao Wang, Xiaokang Yang, Susanto Rahardja, Wei Shen

arXiv:2505.23094v1 Announce Type: new 
Abstract: The rapid development of large language models has revolutionized natural language processing, but their fine-tuning remains computationally expensive,...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23094) | [ğŸ“ Analysis](61350876d56b1327e686327d5b103842.md)

---

### DOPPLER: Dual-Policy Learning for Device Assignment in Asynchronous Dataflow Graphs

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Xinyu Yao, Daniel Bourgeois, Abhinav Jain, Yuxin Tang, Jiawen Yao, Zhimin Ding, Arlei Silva, Chris Jermaine

arXiv:2505.23131v1 Announce Type: new 
Abstract: We study the problem of assigning operations in a dataflow graph to devices to minimize execution time in a work-conserving system, with emphasis on co...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23131) | [ğŸ“ Analysis](a5fb2e5d8c3460a3bc5f6555a0bebe15.md)

---

### Bigger, Regularized, Categorical: High-Capacity Value Functions are Efficient Multi-Task Learners

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Michal Nauman, Marek Cygan, Carmelo Sferrazza, Aviral Kumar, Pieter Abbeel

arXiv:2505.23150v1 Announce Type: new 
Abstract: Recent advances in language modeling and vision stem from training large models on diverse, multi-task data. This paradigm has had limited impact in va...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23150) | [ğŸ“ Analysis](7e8f6a82c7ed928fd6c937b16c3e0a73.md)

---

### Matryoshka Model Learning for Improved Elastic Student Models

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Chetan Verma, Aditya Srinivas Timmaraju, Cho Jui-Hsieh, Suyash Damle, Ngot Bui, Yang Zhang, Wen Chen, Xin Liu, Prateek Jain, Inderjit S Dhillon

arXiv:2505.23337v1 Announce Type: new 
Abstract: Industry-grade ML models are carefully designed to meet rapidly evolving serving constraints, which requires significant resources for model developmen...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23337) | [ğŸ“ Analysis](909955755302c46721e054da065b4bf4.md)

---

### Sentinel: Scheduling Live Streams with Proactive Anomaly Detection in Crowdsourced Cloud-Edge Platforms

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Yuting Li, Shaoyuan Huang, Tengwen Zhang, Cheng Zhang, Xiaofei Wang, Victor C. M. Leung

arXiv:2505.23347v1 Announce Type: new 
Abstract: With the rapid growth of live streaming services, Crowdsourced Cloud-edge service Platforms (CCPs) are playing an increasingly important role in meetin...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23347) | [ğŸ“ Analysis](fbe720561c22e8316e8a11c6d2e99719.md)

---

### Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Maxiu Xiao, Jianglin Lan, Jingxing Yu, Eldert van Henten, Congcong Sun

arXiv:2505.23355v1 Announce Type: new 
Abstract: Climate control is crucial for greenhouse production as it directly affects crop growth and resource use. Reinforcement learning (RL) has received incr...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23355) | [ğŸ“ Analysis](134f4f7cc45159c593f20eafff06dcbf.md)

---

### Meta-Learning Approaches for Speaker-Dependent Voice Fatigue Models

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Roseline Polle, Agnes Norbury, Alexandra Livia Georgescu, Nicholas Cummins, Stefano Goria

arXiv:2505.23378v1 Announce Type: new 
Abstract: Speaker-dependent modelling can substantially improve performance in speech-based health monitoring applications. While mixed-effect models are commonl...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23378) | [ğŸ“ Analysis](07e1a4447aa7f50423a3e7a4c981f0f4.md)

---

### Scaling Offline RL via Efficient and Expressive Shortcut Models

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun

arXiv:2505.22866v1 Announce Type: new 
Abstract: Diffusion and flow models have emerged as powerful generative approaches capable of modeling diverse and multimodal behavior. However, applying these m...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22866) | [ğŸ“ Analysis](bb91c53a150a08969435ad8a17c045de.md)

---

### Directed Graph Grammars for Sequence-based Learning

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Michael Sun, Orion Foo, Gang Liu, Wojciech Matusik, Jie Chen

arXiv:2505.22949v1 Announce Type: new 
Abstract: Directed acyclic graphs (DAGs) are a class of graphs commonly used in practice, with examples that include electronic circuits, Bayesian networks, and ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22949) | [ğŸ“ Analysis](f53161e387c7768b35de8080bda4ea29.md)

---

### Walking the Weight Manifold: a Topological Approach to Conditioning Inspired by Neuromodulation

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Ari S. Benjamin, Kyle Daruwalla, Christian Pehle, Anthony M. Zador

arXiv:2505.22994v1 Announce Type: new 
Abstract: One frequently wishes to learn a range of similar tasks as efficiently as possible, re-using knowledge across tasks. In artificial neural networks, thi...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22994) | [ğŸ“ Analysis](e5eea31e7cbadfc5dc3350051adbfb67.md)

---

### QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Kyle R. Chickering, Bangzheng Li, Muhao Chen

arXiv:2505.23004v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) encode images into visual tokens, aligning visual and textual signals within a shared latent space to facilita...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23004) | [ğŸ“ Analysis](17a819a92ab33992ab5e7b519be54d4d.md)

---

### ProDiff: Prototype-Guided Diffusion for Minimal Information Trajectory Imputation

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Tianci Bu, Le Zhou, Wenchuan Yang, Jianhong Mou, Kang Yang, Suoyi Tan, Feng Yao, Jingyuan Wang, Xin Lu

arXiv:2505.23048v1 Announce Type: new 
Abstract: Trajectory data is crucial for various applications but often suffers from incompleteness due to device limitations and diverse collection scenarios. E...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23048) | [ğŸ“ Analysis](cfc3d5051fd4abc3e9ff4edd54bddb0a.md)

---

### Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Lingkai Kong, Haichuan Wang, Tonghan Wang, Guojun Xiong, Milind Tambe

arXiv:2505.23062v1 Announce Type: new 
Abstract: Incorporating pre-collected offline data from a source environment can significantly improve the sample efficiency of reinforcement learning (RL), but ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23062) | [ğŸ“ Analysis](e144feb86d4f002558b65912a1688cb0.md)

---

### Weight Spectra Induced Efficient Model Adaptation

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Chongjie Si, Xuankun Yang, Muqing Liu, Yadao Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen

arXiv:2505.23099v1 Announce Type: new 
Abstract: Large-scale foundation models have demonstrated remarkable versatility across a wide range of downstream tasks. However, fully fine-tuning these models...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23099) | [ğŸ“ Analysis](5bce1a8818649172b738b876190a579b.md)

---

### The Panaceas for Improving Low-Rank Decomposition in Communication-Efficient Federated Learning

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Shiwei Li, Xiandi Luo, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li

arXiv:2505.23176v1 Announce Type: new 
Abstract: To improve the training efficiency of federated learning (FL), previous research has employed low-rank decomposition techniques to reduce communication...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23176) | [ğŸ“ Analysis](76baf20ee37d0b1f62bb713bbf87adf7.md)

---

### FSL-SAGE: Accelerating Federated Split Learning via Smashed Activation Gradient Estimation

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Srijith Nair, Michael Lin, Amirreza Talebi, Peizhong Ju, Elizabeth Bentley, Jia Liu

arXiv:2505.23182v1 Announce Type: new 
Abstract: Collaborative training methods like Federated Learning (FL) and Split Learning (SL) enable distributed machine learning without sharing raw data. Howev...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23182) | [ğŸ“ Analysis](78de485e95bd026c46202d76c302a92e.md)

---

### Score-based Generative Modeling for Conditional Independence Testing

**Score:** 82.0 | **Published:** 2025-05-31 | **Authors:** Yixin Ren, Chenghou Jin, Yewei Xia, Li Ke, Longtao Huang, Hui Xue, Hao Zhang, Jihong Guan, Shuigeng Zhou

arXiv:2505.23309v1 Announce Type: new 
Abstract: Determining conditional independence (CI) relationships between random variables is a fundamental yet challenging task in machine learning and statisti...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23309) | [ğŸ“ Analysis](42505b4c2abf58fc80dcbe0f967a7558.md)

---

### FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian

**Score:** 80.0 | **Published:** 2025-05-30 | **Authors:** Sara Papi, Marco Gaido, Luisa Bentivogli, Alessio Brutti, Mauro Cettolo, Roberto Gretter, Marco Matassoni, Mohamed Nabih, Matteo Negri

arXiv:2505.22759v1 Announce Type: new 
Abstract: The development of speech foundation models (SFMs) like Whisper and SeamlessM4T has significantly advanced the field of speech processing. However, the...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22759) | [ğŸ“ Analysis](74333fe2ba40ec72bc67df7168bdac35.md)

---

### Preference Learning with Response Time

**Score:** 80.0 | **Published:** 2025-05-31 | **Authors:** Ayush Sawarni, Sahasrajit Sarmasarkar, Vasilis Syrgkanis

arXiv:2505.22820v1 Announce Type: new 
Abstract: This paper investigates the integration of response time data into human preference learning frameworks for more effective reward model elicitation. Wh...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22820) | [ğŸ“ Analysis](43ce6ea9082b05f9f3d97ab0f228534e.md)

---

### Pre-Training Curriculum for Multi-Token Prediction in Language Models

**Score:** 75.0 | **Published:** 2025-05-30 | **Authors:** Ansar Aynetdinov, Alan Akbik

arXiv:2505.22757v1 Announce Type: new 
Abstract: Multi-token prediction (MTP) is a recently proposed pre-training objective for language models. Rather than predicting only the next token (NTP), MTP p...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22757) | [ğŸ“ Analysis](12ab24bf09f2216240eb4013cc457122.md)

---

### LLM-ODDR: A Large Language Model Framework for Joint Order Dispatching and Driver Repositioning

**Score:** 52.1 | **Published:** 2025-05-30 | **Authors:** Tengfei Lyu, Siyuan Feng, Hao Liu, Hai Yang

arXiv:2505.22695v1 Announce Type: new 
Abstract: Ride-hailing platforms face significant challenges in optimizing order dispatching and driver repositioning operations in dynamic urban environments. T...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22695) | [ğŸ“ Analysis](0c431b9a76e90eabf1a8e1152bbaab40.md)

---

### DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning

**Score:** 51.2 | **Published:** 2025-05-30 | **Authors:** Ziyin Zhang, Jiahao Xu, Zhiwei He, Tian Liang, Qiuzhi Liu, Yansi Li, Linfeng Song, Zhengwen Liang, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu

arXiv:2505.23754v1 Announce Type: new 
Abstract: Theorem proving serves as a major testbed for evaluating complex reasoning abilities in large language models (LLMs). However, traditional automated th...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23754) | [ğŸ“ Analysis](9640096705f6ab1a7b05e6acebada1c5.md)

---

### cadrille: Multi-modal CAD Reconstruction with Online Reinforcement Learning

**Score:** 50.0 | **Published:** 2025-05-30 | **Authors:** Maksim Kolodiazhnyi, Denis Tarasov, Dmitrii Zhemchuzhnikov, Alexander Nikulin, Ilya Zisman, Anna Vorontsova, Anton Konushin, Vladislav Kurenkov, Danila Rukhovich

arXiv:2505.22914v1 Announce Type: cross 
Abstract: Computer-Aided Design (CAD) plays a central role in engineering and manufacturing, making it possible to create precise and editable 3D models. Using...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22914) | [ğŸ“ Analysis](04693cd75574f88755c8fcc69d7444be.md)

---

### LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection

**Score:** 47.8 | **Published:** 2025-05-30 | **Authors:** Xinyue Zeng, Haohui Wang, Junhong Lin, Jun Wu, Tyler Cody, Dawei Zhou

arXiv:2505.03793v2 Announce Type: replace-cross 
Abstract: The proliferation of open-sourced Large Language Models (LLMs) and diverse downstream tasks necessitates efficient model selection, given the...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.03793) | [ğŸ“ Analysis](b73448c562fcd30047a7d631e478d8a0.md)

---

### Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling

**Score:** 45.7 | **Published:** 2025-05-30 | **Authors:** Yanzhao Hou, Jiaxiang Geng, Boyu Li, Xiaofeng Tao, Juncheng Wang, Xiaodong Xu, Bing Luo

arXiv:2505.23555v1 Announce Type: new 
Abstract: Federated LoRA has emerged as a promising technique for efficiently fine-tuning large language models (LLMs) on distributed devices by reducing the num...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23555) | [ğŸ“ Analysis](4ce6bbb3f3ab9976aa8b01c5ead9d707.md)

---

### Highly Efficient and Effective LLMs with Multi-Boolean Architectures

**Score:** 44.9 | **Published:** 2025-05-30 | **Authors:** Ba-Hien Tran, Van Minh Nguyen

arXiv:2505.22811v1 Announce Type: cross 
Abstract: Weight binarization has emerged as a promising strategy to drastically reduce the complexity of large language models (LLMs). It is mainly classified...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22811) | [ğŸ“ Analysis](9a54abf3fef752d2d0c0d1b475799c07.md)

---

### Scalable Parameter and Memory Efficient Pretraining for LLM: Recent Algorithmic Advances and Benchmarking

**Score:** 44.8 | **Published:** 2025-05-30 | **Authors:** Athanasios Glentis, Jiaxiang Li, Qiulin Shang, Andi Han, Ioannis Tsaknakis, Quan Wei, Mingyi Hong

arXiv:2505.22922v1 Announce Type: cross 
Abstract: Fueled by their remarkable ability to tackle diverse tasks across multiple domains, large language models (LLMs) have grown at an unprecedented rate,...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22922) | [ğŸ“ Analysis](7e67a163277f46c9e3da1c0e53d5b62c.md)

---

### EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models

**Score:** 44.6 | **Published:** 2025-05-30 | **Authors:** Yuzhen Xiao, Jiahe Song, Yongxin Xu, Ruizhe Zhang, Yiqi Xiao, Xin Lu, Runchuan Zhu, Bowen Jiang, Junfeng Zhao

arXiv:2505.23038v1 Announce Type: new 
Abstract: In-Context Learning (ICL) technique based on Large Language Models (LLMs) has gained prominence in Named Entity Recognition (NER) tasks for its lower c...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23038) | [ğŸ“ Analysis](4944b7697582de3e7dd2f4ed75f2cb92.md)

---

### Accelerating RLHF Training with Reward Variance Increase

**Score:** 44.4 | **Published:** 2025-05-30 | **Authors:** Zonglin Yang, Zhexuan Gu, Houduo Qi, Yancheng Yuan

arXiv:2505.23247v1 Announce Type: cross 
Abstract: Reinforcement learning from human feedback (RLHF) is an essential technique for ensuring that large language models (LLMs) are aligned with human val...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23247) | [ğŸ“ Analysis](a8af982fe6c32c4a656bb98c1f7df325.md)

---

### BioReason: Incentivizing Multimodal Biological Reasoning within a DNA-LLM Model

**Score:** 44.2 | **Published:** 2025-05-30 | **Authors:** Adibvafa Fallahpour, Andrew Magnuson, Purav Gupta, Shihao Ma, Jack Naimer, Arnav Shah, Haonan Duan, Omar Ibrahim, Hani Goodarzi, Chris J. Maddison, Bo Wang

arXiv:2505.23579v1 Announce Type: new 
Abstract: Unlocking deep, interpretable biological reasoning from complex genomic data is a major AI challenge hindering scientific discovery. Current DNA founda...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23579) | [ğŸ“ Analysis](5cc95452868e1558a4031987813d1178.md)

---

### DeepChest: Dynamic Gradient-Free Task Weighting for Effective Multi-Task Learning in Chest X-ray Classification

**Score:** 43.9 | **Published:** 2025-05-30 | **Authors:** Youssef Mohamed, Noran Mohamed, Khaled Abouhashad, Feilong Tang, Sara Atito, Shoaib Jameel, Imran Razzak, Ahmed B. Zaky

arXiv:2505.23595v1 Announce Type: cross 
Abstract: While Multi-Task Learning (MTL) offers inherent advantages in complex domains such as medical imaging by enabling shared representation learning, eff...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23595) | [ğŸ“ Analysis](36f2faf80d6f650bdd73a39143c64ecf.md)

---

### Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time

**Score:** 43.7 | **Published:** 2025-05-30 | **Authors:** Mohamad Chehade, Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Dinesh Manocha, Hao Zhu, Amrit Singh Bedi

arXiv:2505.23729v1 Announce Type: new 
Abstract: Aligning large language models with humans is challenging due to the inherently multifaceted nature of preference feedback. While existing approaches t...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23729) | [ğŸ“ Analysis](9f969e328ab973a5b3dab1aa61c429b3.md)

---

### Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek

**Score:** 42.6 | **Published:** 2025-05-30 | **Authors:** Xueyang Li, Jiahao Li, Yu Song, Yunzhong Lou, Xiangdong Zhou

arXiv:2505.17702v2 Announce Type: replace-cross 
Abstract: The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent rese...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.17702) | [ğŸ“ Analysis](ba288a17506b554dc57acf2f95c57bff.md)

---

### GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation

**Score:** 41.9 | **Published:** 2025-05-30 | **Authors:** Jiashu He, Mingyu Derek Ma, Jinxuan Fan, Dan Roth, Wei Wang, Alejandro Ribeiro

arXiv:2410.08475v3 Announce Type: replace-cross 
Abstract: Existing approaches based on context prompting or reinforcement learning (RL) to improve the reasoning capacities of large language models (L...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2410.08475) | [ğŸ“ Analysis](25672b819e63d4f28b1432b09cfd4689.md)

---

### MoRE: A Mixture of Low-Rank Experts for Adaptive Multi-Task Learning

**Score:** 41.7 | **Published:** 2025-05-30 | **Authors:** Dacao Zhang, Kun Zhang, Shimao Chu, Le Wu, Xin Li, Si Wei

arXiv:2505.22694v1 Announce Type: new 
Abstract: With the rapid development of Large Language Models (LLMs), Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant attention, which aim...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22694) | [ğŸ“ Analysis](832efeaf4de9661c058125dd0a3ffd22.md)

---

### BA-LoRA: Bias-Alleviating Low-Rank Adaptation to Mitigate Catastrophic Inheritance in Large Language Models

**Score:** 41.0 | **Published:** 2025-05-30 | **Authors:** Yupeng Chang, Yi Chang, Yuan Wu

arXiv:2408.04556v5 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable proficiency across various natural language processing (NLP) tasks. However, adapting LLM...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2408.04556) | [ğŸ“ Analysis](5ac5419a0a2df642aeb3e08f4192b853.md)

---

### ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering

**Score:** 40.1 | **Published:** 2025-05-30 | **Authors:** Zexi Liu, Jingyi Chai, Xinyu Zhu, Shuo Tang, Rui Ye, Bo Zhang, Lei Bai, Siheng Chen

arXiv:2505.23723v1 Announce Type: new 
Abstract: The emergence of large language model (LLM)-based agents has significantly advanced the development of autonomous machine learning (ML) engineering. Ho...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23723) | [ğŸ“ Analysis](5c135a56f59b75e821427d17b16b3d30.md)

---

### ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind

**Score:** 39.6 | **Published:** 2025-05-30 | **Authors:** Peixuan Han, Zijia Liu, Jiaxuan You

arXiv:2505.22961v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22961) | [ğŸ“ Analysis](82072d540788df88d130d2cd9f01e8b7.md)

---

### MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration

**Score:** 39.6 | **Published:** 2025-05-30 | **Authors:** Zhitao He (May), Sandeep Polisetty (May), Zhiyuan Fan (May), Yuchen Huang (May), Shujin Wu (May), Yi R. (May),  Fung

arXiv:2505.23224v1 Announce Type: new 
Abstract: In recent years, multimodal large language models (MLLMs) have made significant progress but continue to face inherent challenges in multimodal reasoni...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23224) | [ğŸ“ Analysis](a309c7acc03c2b75328d55531ef0452b.md)

---

### Reasoning-to-Defend: Safety-Aware Reasoning Can Defend Large Language Models from Jailbreaking

**Score:** 39.6 | **Published:** 2025-05-30 | **Authors:** Junda Zhu, Lingyong Yan, Shuaiqiang Wang, Dawei Yin, Lei Sha

arXiv:2502.12970v2 Announce Type: replace 
Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performances across diverse domains. However, how safety of Large Language Models (LLMs)...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2502.12970) | [ğŸ“ Analysis](5ea7b2fa56bf28c1c7b3ff5e0a451d1f.md)

---

### EVOREFUSE: Evolutionary Prompt Optimization for Evaluation and Mitigation of LLM Over-Refusal to Pseudo-Malicious Instructions

**Score:** 39.5 | **Published:** 2025-05-30 | **Authors:** Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaolu Zhang, Jun Zhou, Yuxiang Peng, Li Zheng, Chong Teng, Donghong Ji, Zhuang Li

arXiv:2505.23473v1 Announce Type: new 
Abstract: Large language models (LLMs) frequently refuse to respond to pseudo-malicious instructions: semantically harmless input queries triggering unnecessary ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23473) | [ğŸ“ Analysis](80350614b95cbbda15dea8143fceaab8.md)

---

### LoRA-MGPO: Mitigating Double Descent in Low-Rank Adaptation via Momentum-Guided Perturbation Optimization

**Score:** 39.5 | **Published:** 2025-05-30 | **Authors:** Yupeng Chang, Chenlu Guo, Yi Chang, Yuan Wu

arXiv:2502.14538v2 Announce Type: replace 
Abstract: Parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), enable efficient adaptation of large language models (LLMs) via...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2502.14538) | [ğŸ“ Analysis](30d7828d6b19fc3ebcd09b896ecdc8df.md)

---

### Self-Critique and Refinement for Faithful Natural Language Explanations

**Score:** 39.4 | **Published:** 2025-05-30 | **Authors:** Yingming Wang, Pepa Atanasova

arXiv:2505.22823v1 Announce Type: new 
Abstract: With the rapid development of large language models (LLMs), natural language explanations (NLEs) have become increasingly important for understanding m...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22823) | [ğŸ“ Analysis](f6b823641d1991933f96caeb07194ba0.md)

---

### Diversity-Aware Policy Optimization for Large Language Model Reasoning

**Score:** 38.7 | **Published:** 2025-05-30 | **Authors:** Jian Yao, Ran Cheng, Xingyu Wu, Jibin Wu, Kay Chen Tan

arXiv:2505.23433v1 Announce Type: new 
Abstract: The reasoning capabilities of large language models (LLMs) have advanced rapidly, particularly following the release of DeepSeek R1, which has inspired...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23433) | [ğŸ“ Analysis](0ac76938f849552863ae80d4f2e3eabc.md)

---

### Daunce: Data Attribution through Uncertainty Estimation

**Score:** 38.6 | **Published:** 2025-05-30 | **Authors:** Xingyuan Pan, Chenlu Ye, Joseph Melkonian, Jiaqi W. Ma, Tong Zhang

arXiv:2505.23223v1 Announce Type: new 
Abstract: Training data attribution (TDA) methods aim to identify which training examples influence a model's predictions on specific test data most. By quantify...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23223) | [ğŸ“ Analysis](89a8825dc084a28a41331cf62477f55a.md)

---

### Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms

**Score:** 38.6 | **Published:** 2025-05-30 | **Authors:** Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra

arXiv:2501.13977v3 Announce Type: replace 
Abstract: Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2501.13977) | [ğŸ“ Analysis](a535681ba5f4ef65e8912046dd0d4d21.md)

---

### Afterburner: Reinforcement Learning Facilitates Self-Improving Code Efficiency Optimization

**Score:** 38.5 | **Published:** 2025-05-30 | **Authors:** Mingzhe Du, Luu Tuan Tuan, Yue Liu, Yuhao Qing, Dong Huang, Xinyi He, Qian Liu, Zejun Ma, See-kiong Ng

arXiv:2505.23387v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) generate functionally correct solutions but often fall short in code efficiency, a critical bottleneck for real-world de...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23387) | [ğŸ“ Analysis](d716032d8dfabd73cc639366419369d7.md)

---

### GSQ-Tuning: Group-Shared Exponents Integer in Fully Quantized Training for LLMs On-Device Fine-tuning

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Sifan Zhou, Shuo Wang, Zhihang Yuan, Mingjia Shi, Yuzhang Shang, Dawei Yang

arXiv:2502.12913v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) fine-tuning technologies have achieved remarkable results. However, traditional LLM fine-tuning approaches face ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2502.12913) | [ğŸ“ Analysis](5d21d180d1b1f09fa6c34131fe58d951.md)

---

### Learning to Search for Vehicle Routing with Multiple Time Windows

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Kuan Xu, Zhiguang Cao, Chenlong Zheng, Linong Liu

arXiv:2505.23098v1 Announce Type: new 
Abstract: In this study, we propose a reinforcement learning-based adaptive variable neighborhood search (RL-AVNS) method designed for effectively solving the Ve...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23098) | [ğŸ“ Analysis](152e928403042d375075fe2e0dbede15.md)

---

### Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage

**Score:** 37.9 | **Published:** 2025-05-30 | **Authors:** Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang

arXiv:2505.08167v3 Announce Type: replace 
Abstract: The rapid development of large language models (LLMs) has provided significant support and opportunities for the advancement of domain-specific LLM...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.08167) | [ğŸ“ Analysis](32c66f9306233a120a40994fdd1eea1c.md)

---

### One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory

**Score:** 37.8 | **Published:** 2025-05-30 | **Authors:** Chenhao Zheng, Jieyu Zhang, Mohammadreza Salehi, Ziqi Gao, Vishnu Iyengar, Norimasa Kobori, Quan Kong, Ranjay Krishna

arXiv:2505.23617v1 Announce Type: cross 
Abstract: Effective video tokenization is critical for scaling transformer models for long videos. Current approaches tokenize videos using space-time patches,...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23617) | [ğŸ“ Analysis](1ce4060fdd455540f63666f099f64072.md)

---

### Table-R1: Inference-Time Scaling for Table Reasoning

**Score:** 37.6 | **Published:** 2025-05-30 | **Authors:** Zheyuan Yang, Lyuhao Chen, Arman Cohan, Yilun Zhao

arXiv:2505.23621v1 Announce Type: new 
Abstract: In this work, we present the first study to explore inference-time scaling on table reasoning tasks. We develop and evaluate two post-training strategi...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23621) | [ğŸ“ Analysis](d58df1a630c4f61d2b0d5b1501107184.md)

---

### MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment

**Score:** 37.5 | **Published:** 2025-05-30 | **Authors:** John Halloran

arXiv:2505.23634v1 Announce Type: new 
Abstract: The model context protocol (MCP) has been widely adapted as an open standard enabling the seamless integration of generative AI agents. However, recent...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23634) | [ğŸ“ Analysis](c061cd2d2d923ce97f5a1eaf64064a51.md)

---

### LLMs Can Achieve High-quality Simultaneous Machine Translation as Efficiently as Offline

**Score:** 37.4 | **Published:** 2025-05-30 | **Authors:** Biao Fu, Minpeng Liao, Kai Fan, Chengxi Li, Liang Zhang, Yidong Chen, Xiaodong Shi

arXiv:2504.09570v2 Announce Type: replace 
Abstract: When the complete source sentence is provided, Large Language Models (LLMs) perform excellently in offline machine translation even with a simple p...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2504.09570) | [ğŸ“ Analysis](4afb85a0fc2b1142b810a3cc30b02f1b.md)

---

### HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model

**Score:** 37.1 | **Published:** 2025-05-30 | **Authors:** Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu

arXiv:2503.12941v2 Announce Type: replace 
Abstract: Instruction tuning is widely used to improve a pre-trained Multimodal Large Language Model (MLLM) by training it on curated task-specific datasets,...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2503.12941) | [ğŸ“ Analysis](47c2ce6cf6cfea1656e63dedb740e05b.md)

---

### Structure-Enhanced Protein Instruction Tuning: Towards General-Purpose Protein Understanding with LLMs

**Score:** 36.6 | **Published:** 2025-05-30 | **Authors:** Wei Wu, Chao Wang, Liyi Chen, Mingze Yin, Yiheng Zhu, Kun Fu, Jieping Ye, Hui Xiong, Zheng Wang

arXiv:2410.03553v3 Announce Type: replace 
Abstract: Proteins, as essential biomolecules, play a central role in biological processes, including metabolic reactions and DNA replication. Accurate predi...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2410.03553) | [ğŸ“ Analysis](3bf215c47f4a2b57da02ccf6bfebc2e1.md)

---

### Pangu Embedded: An Efficient Dual-system LLM Reasoner with Metacognition

**Score:** 36.5 | **Published:** 2025-05-30 | **Authors:** Hanting Chen (and Other Contributors), Yasheng Wang (and Other Contributors), Kai Han (and Other Contributors), Dong Li (and Other Contributors), Lin Li (and Other Contributors), Zhenni Bi (and Other Contributors), Jinpeng Li (and Other Contributors), Haoyu Wang (and Other Contributors), Fei Mi (and Other Contributors), Mingjian Zhu (and Other Contributors), Bin Wang (and Other Contributors), Kaikai Song (and Other Contributors), Yifei Fu (and Other Contributors), Xu He (and Other Contributors), Yu Luo (and Other Contributors), Chong Zhu (and Other Contributors), Quan He (and Other Contributors), Xueyu Wu (and Other Contributors), Wei He (and Other Contributors), Hailin Hu (and Other Contributors), Yehui Tang (and Other Contributors), Dacheng Tao (and Other Contributors), Xinghao Chen (and Other Contributors), Yunhe Wang (and Other Contributors)

arXiv:2505.22375v2 Announce Type: replace 
Abstract: This work presents Pangu Embedded, an efficient Large Language Model (LLM) reasoner developed on Ascend Neural Processing Units (NPUs), featuring f...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22375) | [ğŸ“ Analysis](b254c55ad321f5ae57cc8cc7a58ac851.md)

---

### GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Tao Feng, Yihang Sun, Jiaxuan You

arXiv:2503.12600v2 Announce Type: replace 
Abstract: The powerful capabilities of Large Language Models (LLMs) have led to their growing use in evaluating human-generated content, particularly in eval...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2503.12600) | [ğŸ“ Analysis](4e4156bee9b074c148fd55769165f374.md)

---

### STeCa: Step-level Trajectory Calibration for LLM Agent Learning

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Hanlin Wang, Jian Wang, Chak Tou Leong, Wenjie Li

arXiv:2502.14276v2 Announce Type: replace-cross 
Abstract: Large language model (LLM)-based agents have shown promise in tackling complex tasks by interacting dynamically with the environment. Existin...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2502.14276) | [ğŸ“ Analysis](f9ced87490a0bdc3245ff0e1c3337a65.md)

---

### Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters

**Score:** 36.3 | **Published:** 2025-05-30 | **Authors:** Hayden Moore, Sirui Qi, Ninad Hogade, Dejan Milojicic, Cullen Bash, Sudeep Pasricha

arXiv:2505.23554v1 Announce Type: cross 
Abstract: In recent years, Large Language Models (LLM) such as ChatGPT, CoPilot, and Gemini have been widely adopted in different areas. As the use of LLMs con...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23554) | [ğŸ“ Analysis](b12abb24ec5b4b20376880a9f6e654ae.md)

---

### Pseudo Multi-Source Domain Generalization: Bridging the Gap Between Single and Multi-Source Domain Generalization

**Score:** 36.2 | **Published:** 2025-05-30 | **Authors:** Shohei Enomoto

arXiv:2505.23173v1 Announce Type: new 
Abstract: Deep learning models often struggle to maintain performance when deployed on data distributions different from their training data, particularly in rea...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23173) | [ğŸ“ Analysis](07765244da5f2c68327780096280ac17.md)

---

### Training Language Models to Generate Quality Code with Program Analysis Feedback

**Score:** 36.2 | **Published:** 2025-05-30 | **Authors:** Feng Yao, Zilong Wang, Liyuan Liu, Junxia Cui, Li Zhong, Xiaohan Fu, Haohui Mai, Vish Krishnan, Jianfeng Gao, Jingbo Shang

arXiv:2505.22704v1 Announce Type: new 
Abstract: Code generation with large language models (LLMs), often termed vibe coding, is increasingly adopted in production but fails to ensure code quality, pa...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22704) | [ğŸ“ Analysis](d60e8e83eccd27feff7f306dc9043fcc.md)

---

### Loss-Guided Model Sharing and Local Learning Correction in Decentralized Federated Learning for Crop Disease Classification

**Score:** 36.2 | **Published:** 2025-05-30 | **Authors:** Denis Mamba Kabala, Adel Hafiane, Laurent Bobelin, Raphael Canals

arXiv:2505.23063v1 Announce Type: new 
Abstract: Crop disease detection and classification is a critical challenge in agriculture, with major implications for productivity, food security, and environm...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23063) | [ğŸ“ Analysis](f844f00481555099df44cfd7c993422e.md)

---

### Proximalized Preference Optimization for Diverse Feedback Types: A Decomposed Perspective on DPO

**Score:** 36.0 | **Published:** 2025-05-30 | **Authors:** Kaiyang Guo, Yinchuan Li, Zhitang Chen

arXiv:2505.23316v1 Announce Type: new 
Abstract: Direct alignment methods typically optimize large language models (LLMs) by contrasting the likelihoods of preferred versus dispreferred responses. Whi...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23316) | [ğŸ“ Analysis](a9ef727383e3a41c6198a924460f9647.md)

---

### Detecting Stealthy Backdoor Samples based on Intra-class Distance for Large Language Models

**Score:** 36.0 | **Published:** 2025-05-30 | **Authors:** Jinwen Chen, Hainan Zhang, Fei Sun, Qinnan Zhang, Sijia Wen, Ziwei Wang, Zhiming Zheng

arXiv:2505.23015v1 Announce Type: new 
Abstract: Fine-tuning LLMs with datasets containing stealthy backdoors from publishers poses security risks to downstream applications. Mainstream detection meth...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23015) | [ğŸ“ Analysis](88cf260905237993fa309d806bf125c4.md)

---

### BugWhisperer: Fine-Tuning LLMs for SoC Hardware Vulnerability Detection

**Score:** 35.8 | **Published:** 2025-05-30 | **Authors:** Shams Tarek, Dipayan Saha, Sujan Kumar Saha, Farimah Farahmandi

arXiv:2505.22878v1 Announce Type: cross 
Abstract: The current landscape of system-on-chips (SoCs) security verification faces challenges due to manual, labor-intensive, and inflexible methodologies. ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22878) | [ğŸ“ Analysis](c5955174c7bc0641c184cd2dde999587.md)

---

### Understanding Bias Reinforcement in LLM Agents Debate

**Score:** 35.5 | **Published:** 2025-05-30 | **Authors:** Jihwan Oh, Minchan Jeong, Jongwoo Ko, Se-Young Yun

arXiv:2503.16814v2 Announce Type: replace-cross 
Abstract: Large Language Models $($LLMs$)$ solve complex problems using training-free methods like prompt engineering and in-context learning, yet ensu...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2503.16814) | [ğŸ“ Analysis](dbebedc999bbc077bc30a349365b87a3.md)

---

### AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models

**Score:** 35.4 | **Published:** 2025-05-30 | **Authors:** Jinchuan Zhang, Lu Yin, Yan Zhou, Songlin Hu

arXiv:2505.23020v1 Announce Type: cross 
Abstract: The acquisition of agentic capabilities has transformed LLMs from "knowledge providers" to "action executors", a trend that while expanding LLMs' cap...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23020) | [ğŸ“ Analysis](a5cc25f751a58324e60d01470506fb5e.md)

---

### Length-Controlled Margin-Based Preference Optimization without Reference Model

**Score:** 35.1 | **Published:** 2025-05-30 | **Authors:** Gengxu Li, Tingyu Xia, Yi Chang, Yuan Wu

arXiv:2502.14643v2 Announce Type: replace 
Abstract: Direct Preference Optimization (DPO) is a widely adopted offline algorithm for preference-based reinforcement learning from human feedback (RLHF), ...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2502.14643) | [ğŸ“ Analysis](fcb19b58e28079feb1e2ec2d1a3dc409.md)

---

### PGLearn -- An Open-Source Learning Toolkit for Optimal Power Flow

**Score:** 35.0 | **Published:** 2025-05-30 | **Authors:** Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck

arXiv:2505.22825v1 Announce Type: cross 
Abstract: Machine Learning (ML) techniques for Optimal Power Flow (OPF) problems have recently garnered significant attention, reflecting a broader trend of le...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22825) | [ğŸ“ Analysis](5cd4de52b77b2810e4b93b77ed4fef53.md)

---


*Last updated: 2025-05-31 09:25:12 UTC*
