# Learning to Search for Vehicle Routing with Multiple Time Windows

**Authors:** Kuan Xu, Zhiguang Cao, Chenlong Zheng, Linong Liu

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 38.3/100

## Abstract

arXiv:2505.23098v1 Announce Type: new 
Abstract: In this study, we propose a reinforcement learning-based adaptive variable neighborhood search (RL-AVNS) method designed for effectively solving the Vehicle Routing Problem with Multiple Time Windows (VRPMTW). Unlike traditional adaptive approaches that rely solely on historical operator performance, our method integrates a reinforcement learning framework to dynamically select neighborhood operators based on real-time solution states and learned experience. We introduce a fitness metric that quantifies customers' temporal flexibility to improve the shaking phase, and employ a transformer-based neural policy network to intelligently guide operator selection during the local search. Extensive computational experiments are conducted on realistic scenarios derived from the replenishment of unmanned vending machines, characterized by multiple clustered replenishment windows. Results demonstrate that RL-AVNS significantly outperforms traditional variable neighborhood search (VNS), adaptive VNS (AVNS), and state-of-the-art learning-based heuristics, achieving substantial improvements in solution quality and computational efficiency across various instance scales and time window complexities. Particularly notable is the algorithm's capability to generalize effectively to problem instances not encountered during training, underscoring its practical utility for complex logistics scenarios.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 32.0/100  
**Sentiment Score:** 56.5/100

**Justification:** High innovation indicators (score: 30); Strong impact potential (score: 32); Contains key LLM terms (bonus: 5)

## Keywords

based, learning, search, time, adaptive, avns, multiple, neighborhood, windows, computational

## Links

- [Paper URL](https://arxiv.org/abs/2505.23098)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
