# Scaling Offline RL via Efficient and Expressive Shortcut Models

**Authors:** Nicolas Espinosa-Dice, Yiyi Zhang, Yiding Chen, Bradley Guo, Owen Oertell, Gokul Swamy, Kiante Brantley, Wen Sun

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 82.0/100

## Abstract

arXiv:2505.22866v1 Announce Type: new 
Abstract: Diffusion and flow models have emerged as powerful generative approaches capable of modeling diverse and multimodal behavior. However, applying these models to offline reinforcement learning (RL) remains challenging due to the iterative nature of their noise sampling processes, making policy optimization difficult. In this paper, we introduce Scalable Offline Reinforcement Learning (SORL), a new offline RL algorithm that leverages shortcut models - a novel class of generative models - to scale both training and inference. SORL's policy can capture complex data distributions and can be trained simply and efficiently in a one-stage training procedure. At test time, SORL introduces both sequential and parallel inference scaling by using the learned Q-function as a verifier. We demonstrate that SORL achieves strong performance across a range of offline RL tasks and exhibits positive scaling behavior with increased test-time compute. We release the code at nico-espinosadice.github.io/projects/sorl.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 70.0/100  
**Sentiment Score:** 85.0/100

**Justification:** This paper addresses a significant challenge in offline RL â€“ scaling generative models like diffusion and flow models for policy optimization. The introduction of 'shortcut models' appears to be a novel approach to address the iterative sampling bottleneck, and the reported scaling behavior with increased compute is encouraging. While the abstract is concise, it suggests a well-structured approach with both training and inference improvements, making it a promising contribution to the field.

## Keywords

models, offline, sorl, rl, offline rl, scaling, behavior, generative, inference, learning

## Links

- [Paper URL](https://arxiv.org/abs/2505.22866)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
