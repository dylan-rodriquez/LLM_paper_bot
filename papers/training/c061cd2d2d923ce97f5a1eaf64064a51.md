# MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment

**Authors:** John Halloran

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 37.5/100

## Abstract

arXiv:2505.23634v1 Announce Type: new 
Abstract: The model context protocol (MCP) has been widely adapted as an open standard enabling the seamless integration of generative AI agents. However, recent work has shown the MCP is susceptible to retrieval-based "falsely benign" attacks (FBAs), allowing malicious system access and credential theft, but requiring that users download compromised files directly to their systems. Herein, we show that the threat model of MCP-based attacks is significantly broader than previously thought, i.e., attackers need only post malicious content online to deceive MCP agents into carrying out their attacks on unsuspecting victims' systems.
  To improve alignment guardrails against such attacks, we introduce a new MCP dataset of FBAs and (truly) benign samples to explore the effectiveness of direct preference optimization (DPO) for the refusal training of large language models (LLMs). While DPO improves model guardrails against such attacks, we show that the efficacy of refusal learning varies drastically depending on the model's original post-training alignment scheme--e.g., GRPO-based LLMs learn to refuse extremely poorly. Thus, to further improve FBA refusals, we introduce Retrieval Augmented Generation for Preference alignment (RAG-Pref), a novel preference alignment strategy based on RAG. We show that RAG-Pref significantly improves the ability of LLMs to refuse FBAs, particularly when combined with DPO alignment, thus drastically improving guardrails against MCP-based attacks.

## Analysis

**Innovation Score:** 40.0/100
**Impact Score:** 8.0/100  
**Sentiment Score:** 48.6/100

**Justification:** High innovation indicators (score: 40); Contains key LLM terms (bonus: 10)

## Keywords

mcp, alignment, attacks, based, model, preference, benign, dpo, fbas, guardrails

## Links

- [Paper URL](https://arxiv.org/abs/2505.23634)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
