# Grower-in-the-Loop Interactive Reinforcement Learning for Greenhouse Climate Control

**Authors:** Maxiu Xiao, Jianglin Lan, Jingxing Yu, Eldert van Henten, Congcong Sun

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.23355v1 Announce Type: new 
Abstract: Climate control is crucial for greenhouse production as it directly affects crop growth and resource use. Reinforcement learning (RL) has received increasing attention in this field, but still faces challenges, including limited training efficiency and high reliance on initial learning conditions. Interactive RL, which combines human (grower) input with the RL agent's learning, offers a potential solution to overcome these challenges. However, interactive RL has not yet been applied to greenhouse climate control and may face challenges related to imperfect inputs. Therefore, this paper aims to explore the possibility and performance of applying interactive RL with imperfect inputs into greenhouse climate control, by: (1) developing three representative interactive RL algorithms tailored for greenhouse climate control (reward shaping, policy shaping and control sharing); (2) analyzing how input characteristics are often contradicting, and how the trade-offs between them make grower's inputs difficult to perfect; (3) proposing a neural network-based approach to enhance the robustness of interactive RL agents under limited input availability; (4) conducting a comprehensive evaluation of the three interactive RL algorithms with imperfect inputs in a simulated greenhouse environment. The demonstration shows that interactive RL incorporating imperfect grower inputs has the potential to improve the performance of the RL agent. RL algorithms that influence action selection, such as policy shaping and control sharing, perform better when dealing with imperfect inputs, achieving 8.4% and 6.8% improvement in profit, respectively. In contrast, reward shaping, an algorithm that manipulates the reward function, is sensitive to imperfect inputs and leads to a 9.4% decrease in profit. This highlights the importance of selecting an appropriate mechanism when incorporating imperfect inputs.

## Analysis

**Innovation Score:** 65.0/100
**Impact Score:** 80.0/100  
**Sentiment Score:** 75.0/100

**Justification:** The paper addresses a relevant and important problem â€“ improving efficiency and robustness of RL in greenhouse climate control, a field with significant practical implications. The exploration of interactive RL, particularly acknowledging imperfect grower input, is a sensible and potentially impactful direction. While the development of three algorithms is a good start, the abstract doesn't detail the novelty of these algorithms beyond simply applying interactive RL techniques. The focus on contradicting inputs is also a strong point, suggesting a realistic approach.

## Keywords

rl, inputs, interactive, control, imperfect, interactive rl, greenhouse, imperfect inputs, climate, climate control

## Links

- [Paper URL](https://arxiv.org/abs/2505.23355)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
