# Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms

**Authors:** Rajvardhan Oak, Muhammad Haroon, Claire Jo, Magdalena Wojcieszak, Anshuman Chhabra

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 38.6/100

## Abstract

arXiv:2501.13977v3 Announce Type: replace 
Abstract: Social media platforms utilize Machine Learning (ML) and Artificial Intelligence (AI) powered recommendation algorithms to maximize user engagement, which can result in inadvertent exposure to harmful content. Current moderation efforts, reliant on classifiers trained with extensive human-annotated data, struggle with scalability and adapting to new forms of harm. To address these challenges, we propose a novel re-ranking approach using Large Language Models (LLMs) in zero-shot and few-shot settings. Our method dynamically assesses and re-ranks content sequences, effectively mitigating harmful content exposure without requiring extensive labeled data. Alongside traditional ranking metrics, we also introduce two new metrics to evaluate the effectiveness of re-ranking in reducing exposure to harmful content. Through experiments on three datasets, three models and across three configurations, we demonstrate that our LLM-based approach significantly outperforms existing proprietary moderation approaches, offering a scalable and adaptable solution for harm mitigation.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 53.0/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)

## Keywords

content, exposure, harmful, harmful content, ranking, exposure harmful, models, approach, data, extensive

## Links

- [Paper URL](https://arxiv.org/abs/2501.13977)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
