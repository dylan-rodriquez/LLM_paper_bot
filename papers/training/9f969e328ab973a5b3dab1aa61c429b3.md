# Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time

**Authors:** Mohamad Chehade, Soumya Suvra Ghosal, Souradip Chakraborty, Avinash Reddy, Dinesh Manocha, Hao Zhu, Amrit Singh Bedi

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 43.7/100

## Abstract

arXiv:2505.23729v1 Announce Type: new 
Abstract: Aligning large language models with humans is challenging due to the inherently multifaceted nature of preference feedback. While existing approaches typically frame this as a multi-objective optimization problem, they often overlook how humans actually make decisions. Research on bounded rationality suggests that human decision making follows satisficing strategies-optimizing primary objectives while ensuring others meet acceptable thresholds. To bridge this gap and operationalize the notion of satisficing alignment, we propose SITAlign: an inference time framework that addresses the multifaceted nature of alignment by maximizing a primary objective while satisfying threshold-based constraints on secondary criteria. We provide theoretical insights by deriving sub-optimality bounds of our satisficing based inference alignment approach. We empirically validate SITAlign's performance through extensive experimentation on multiple benchmarks. For instance, on the PKU-SafeRLHF dataset with the primary objective of maximizing helpfulness while ensuring a threshold on harmlessness, SITAlign outperforms the state-of-the-art multi objective decoding strategy by a margin of 22.3% in terms of GPT-4 win-tie rate for helpfulness reward while adhering to the threshold on harmlessness.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 8.0/100  
**Sentiment Score:** 57.1/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 15)

## Keywords

alignment, objective, satisficing, inference, primary, sitalign, threshold, based, bounded, bounded rationality

## Links

- [Paper URL](https://arxiv.org/abs/2505.23729)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
