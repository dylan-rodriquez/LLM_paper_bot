# Can We Infer Confidential Properties of Training Data from LLMs?

**Authors:** Penguin Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri

**Published:** 2025-06-13 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 92.0/100

## Abstract

arXiv:2506.10364v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly fine-tuned on domain-specific datasets to support applications in fields such as healthcare, finance, and law. These fine-tuning datasets often have sensitive and confidential dataset-level properties -- such as patient demographics or disease prevalence -- that are not intended to be revealed. While prior work has studied property inference attacks on discriminative models (e.g., image classification models) and generative models (e.g., GANs for image data), it remains unclear if such attacks transfer to LLMs. In this work, we introduce PropInfer, a benchmark task for evaluating property inference in LLMs under two fine-tuning paradigms: question-answering and chat-completion. Built on the ChatDoctor dataset, our benchmark includes a range of property types and task configurations. We further propose two tailored attacks: a prompt-based generation attack and a shadow-model attack leveraging word frequency signals. Empirical evaluations across multiple pretrained LLMs show the success of our attacks, revealing a previously unrecognized vulnerability in LLMs.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 85.0/100

**Justification:** This paper addresses a highly relevant and timely problem â€“ the potential for LLMs to leak confidential information from their training data. The introduction of PropInfer as a benchmark and the proposal of tailored attacks are strong methodological contributions. While the attacks themselves may build on existing property inference techniques, adapting them to the LLM context is novel and important, and the focus on both question-answering and chat-completion paradigms adds to the work's value.

## Keywords

llms, attacks, models, fine, property, attack, benchmark, confidential, data, dataset

## Links

- [Paper URL](https://arxiv.org/abs/2506.10364)

---
*Auto-generated on 2025-06-13 09:29:22 UTC*
