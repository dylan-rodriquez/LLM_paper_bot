# Development and Validation of SXI++ LNM Algorithm for Sepsis Prediction

**Authors:** Dharambir Mahto, Prashant Yadav, Mahesh Banavar, Jim Keany, Alan T Joseph, Srinivas Kilambi

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 92.0/100

## Abstract

arXiv:2505.22840v1 Announce Type: new 
Abstract: Sepsis is a life-threatening condition affecting over 48.9 million people globally and causing 11 million deaths annually. Despite medical advancements, predicting sepsis remains a challenge due to non-specific symptoms and complex pathophysiology. The SXI++ LNM is a machine learning scoring system that refines sepsis prediction by leveraging multiple algorithms and deep neural networks. This study aims to improve robustness in clinical applications and evaluates the predictive performance of the SXI++ LNM for sepsis prediction. The model, utilizing a deep neural network, was trained and tested using multiple scenarios with different dataset distributions. The model's performance was assessed against unseen test data, and accuracy, precision, and area under the curve (AUC) were calculated. THE SXI++ LNM outperformed the state of the art in three use cases, achieving an AUC of 0.99 (95% CI: 0.98-1.00). The model demonstrated a precision of 99.9% (95% CI: 99.8-100.0) and an accuracy of 99.99% (95% CI: 99.98-100.0), maintaining high reliability.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 80.0/100

**Justification:** The research addresses a critical medical problem (sepsis prediction) with a potentially high-impact solution. The reported AUC of 0.99 is impressive, suggesting a robust model. While leveraging deep neural networks isn't entirely novel, the 'SXI++ LNM' refinement and its performance against state-of-the-art methods indicate a worthwhile contribution. The focus on multiple dataset distributions strengthens the study's rigor.

## Keywords

99, sepsis, lnm, sxi, sxi lnm, 95, 95 ci, 99 95, ci, model

## Links

- [Paper URL](https://arxiv.org/abs/2505.22840)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
