# DINGO: Constrained Inference for Diffusion LLMs

**Authors:** Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 80.0/100

## Abstract

arXiv:2505.23061v1 Announce Type: new 
Abstract: Diffusion LLMs have emerged as a promising alternative to conventional autoregressive LLMs, offering significant potential for improved runtime efficiency. However, existing diffusion models lack the ability to provably enforce user-specified formal constraints, such as regular expressions, which makes them unreliable for tasks that require structured outputs, such as fixed-schema JSON generation. Unlike autoregressive models that generate tokens sequentially, diffusion LLMs predict a block of tokens in parallel. This parallelism makes traditional constrained decoding algorithms, which are designed for sequential token prediction, ineffective at preserving the true output distribution. To address this limitation, we propose DINGO, a dynamic programming-based constrained decoding strategy that is both efficient and provably distribution-preserving. DINGO enables sampling of output strings with the highest probability under the model's predicted distribution, while strictly satisfying any user-specified regular expression. On standard symbolic math and JSON generation benchmarks, DINGO achieves up to a 68 percentage point improvement over unconstrained inference

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 70.0/100  
**Sentiment Score:** 85.0/100

**Justification:** This paper addresses a crucial limitation of diffusion LLMs – the inability to enforce constraints – which hinders their use in practical applications requiring structured outputs. The proposed DINGO approach, leveraging dynamic programming, appears to be a novel and effective solution for constrained decoding in this context. The claim of distribution preservation is particularly strong, and the problem is well-motivated, suggesting a positive reception from the community.

## Keywords

diffusion, dingo, llms, constrained, diffusion llms, distribution, autoregressive, constrained decoding, decoding, generation

## Links

- [Paper URL](https://arxiv.org/abs/2505.23061)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
