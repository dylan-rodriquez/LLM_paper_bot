# Generation Papers

This directory contains papers related to generation in large language models and AI.

## Papers (4 total)

### DINGO: Constrained Inference for Diffusion LLMs

**Score:** 80.0 | **Published:** 2025-05-31 | **Authors:** Tarun Suresh, Debangshu Banerjee, Shubham Ugare, Sasa Misailovic, Gagandeep Singh

arXiv:2505.23061v1 Announce Type: new 
Abstract: Diffusion LLMs have emerged as a promising alternative to conventional autoregressive LLMs, offering significant potential for improved runtime efficie...

[📄 Full Paper](https://arxiv.org/abs/2505.23061) | [📝 Analysis](aed682f72a5d0b2e545ce6a810580aa6.md)

---

### Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency

**Score:** 37.8 | **Published:** 2025-05-30 | **Authors:** Roman Vashurin, Maiya Goloburda, Albina Ilina, Aleksandr Rubashevskii, Preslav Nakov, Artem Shelmanov, Maxim Panov

arXiv:2502.04964v4 Announce Type: replace 
Abstract: Uncertainty quantification (UQ) methods for Large Language Models (LLMs) encompass a variety of approaches, with two major types being particularly...

[📄 Full Paper](https://arxiv.org/abs/2502.04964) | [📝 Analysis](75beed468013cfdf0602c753dea81204.md)

---

### SimGRAG: Leveraging Similar Subgraphs for Knowledge Graphs Driven Retrieval-Augmented Generation

**Score:** 37.4 | **Published:** 2025-05-30 | **Authors:** Yuzheng Cai, Zhenyue Guo, Yiwen Pei, Wanrui Bian, Weiguo Zheng

arXiv:2412.15272v2 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have shown impressive versatility across various tasks. To eliminate their hallucinations, retr...

[📄 Full Paper](https://arxiv.org/abs/2412.15272) | [📝 Analysis](6abc11d53cf1a21d1b0ec161313cf0c6.md)

---

### Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation

**Score:** 35.4 | **Published:** 2025-05-30 | **Authors:** Hongxiang Zhang, Hao Chen, Tianyi Zhang, Muhao Chen

arXiv:2505.23657v1 Announce Type: new 
Abstract: Recent decoding methods improve the factuality of large language models~(LLMs) by refining how the next token is selected during generation. These meth...

[📄 Full Paper](https://arxiv.org/abs/2505.23657) | [📝 Analysis](fdd54ed79a8ac1f08c737f3d12158741.md)

---


*Last updated: 2025-05-31 09:25:12 UTC*
