# Uncertainty Quantification for LLMs through Minimum Bayes Risk: Bridging Confidence and Consistency

**Authors:** Roman Vashurin, Maiya Goloburda, Albina Ilina, Aleksandr Rubashevskii, Preslav Nakov, Artem Shelmanov, Maxim Panov

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 37.8/100

## Abstract

arXiv:2502.04964v4 Announce Type: replace 
Abstract: Uncertainty quantification (UQ) methods for Large Language Models (LLMs) encompass a variety of approaches, with two major types being particularly prominent: information-based, which focus on model confidence expressed as token probabilities, and consistency-based, which assess the semantic relationship between multiple outputs generated using repeated sampling. Several recent methods have combined these two approaches to boost UQ performance. However, they sometimes fail to outperform much simpler baseline methods. Our work discusses the fundamental approach to constructing uncertainty measures that directly links uncertainty with the minimum Bayes risks achieved by LLM decoding. Building on these findings, we propose a novel approach to integrating model confidence with output consistency, resulting in a family of efficient and robust UQ methods. Our investigation reveals distinctive characteristics of LLMs as probabilistic models, which help to explain why these UQ methods underperform in certain tasks. Based on these findings, we propose a new way of synthesizing model confidence and output consistency, leading to a family of efficient and robust UQ methods. We evaluate our approach across various tasks such as question answering, abstractive summarization, and machine translation, demonstrating sizable improvements over state-of-the-art UQ approaches.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 55.1/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)

## Keywords

methods, uq, confidence, consistency, uncertainty, uq methods, approach, approaches, based, llms

## Links

- [Paper URL](https://arxiv.org/abs/2502.04964)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
