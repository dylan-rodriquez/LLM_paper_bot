# Improving QA Efficiency with DistilBERT: Fine-Tuning and Inference on mobile Intel CPUs

**Authors:** Ngeyen Yinkfu

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 36.4/100

## Abstract

arXiv:2505.22937v1 Announce Type: new 
Abstract: This study presents an efficient transformer-based question-answering (QA) model optimized for deployment on a 13th Gen Intel i7-1355U CPU, using the Stanford Question Answering Dataset (SQuAD) v1.1. Leveraging exploratory data analysis, data augmentation, and fine-tuning of a DistilBERT architecture, the model achieves a validation F1 score of 0.6536 with an average inference time of 0.1208 seconds per question. Compared to a rule-based baseline (F1: 0.3124) and full BERT-based models, our approach offers a favorable trade-off between accuracy and computational efficiency. This makes it well-suited for real-time applications on resource-constrained systems. The study includes systematic evaluation of data augmentation strategies and hyperparameter configurations, providing practical insights into optimizing transformer models for CPU-based inference.

## Analysis

**Innovation Score:** 10.0/100
**Impact Score:** 24.0/100  
**Sentiment Score:** 56.0/100

**Justification:** Strong impact potential (score: 24); Contains key LLM terms (bonus: 10)

## Keywords

based, data, inference, question, answering, augmentation, cpu, data augmentation, distilbert, efficiency

## Links

- [Paper URL](https://arxiv.org/abs/2505.22937)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
