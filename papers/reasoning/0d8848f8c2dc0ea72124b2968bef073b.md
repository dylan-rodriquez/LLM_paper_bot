# Climate Finance Bench

**Authors:** Rafik Mankour, Yassine Chafai, Hamada Saleh, Ghassen Ben Hassine, Thibaud Barreau, Peter Tankov

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.22752v1 Announce Type: new 
Abstract: Climate Finance Bench introduces an open benchmark that targets question-answering over corporate climate disclosures using Large Language Models. We curate 33 recent sustainability reports in English drawn from companies across all 11 GICS sectors and annotate 330 expert-validated question-answer pairs that span pure extraction, numerical reasoning, and logical reasoning. Building on this dataset, we propose a comparison of RAG (retrieval-augmented generation) approaches. We show that the retriever's ability to locate passages that actually contain the answer is the chief performance bottleneck. We further argue for transparent carbon reporting in AI-for-climate applications, highlighting advantages of techniques such as Weight Quantization.

## Analysis

**Innovation Score:** 65.0/100
**Impact Score:** 75.0/100  
**Sentiment Score:** 80.0/100

**Justification:** This paper addresses a highly relevant and timely problem â€“ leveraging LLMs for climate finance analysis. The creation of a curated, expert-validated dataset is a strong methodological contribution. While the RAG comparison isn't groundbreaking in itself, identifying the retriever as a bottleneck is a valuable insight, and the mention of carbon-aware AI techniques adds further value. The work appears well-structured and clearly presented, suggesting a positive reception within the AI and climate communities.

## Keywords

climate, answer, bench, climate finance, finance, finance bench, question, reasoning, 11, 11 gics

## Links

- [Paper URL](https://arxiv.org/abs/2505.22752)

---
*Auto-generated on 2025-05-30 13:44:12 UTC*
