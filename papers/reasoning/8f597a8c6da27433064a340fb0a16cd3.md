# From Chat Logs to Collective Insights: Aggregative Question Answering

**Authors:** Wentao Zhang, Woojeong Kim, Yuntian Deng

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 39.3/100

## Abstract

arXiv:2505.23765v1 Announce Type: new 
Abstract: Conversational agents powered by large language models (LLMs) are rapidly becoming integral to our daily interactions, generating unprecedented amounts of conversational data. Such datasets offer a powerful lens into societal interests, trending topics, and collective concerns. Yet, existing approaches typically treat these interactions as independent and miss critical insights that could emerge from aggregating and reasoning across large-scale conversation logs. In this paper, we introduce Aggregative Question Answering, a novel task requiring models to reason explicitly over thousands of user-chatbot interactions to answer aggregative queries, such as identifying emerging concerns among specific demographics. To enable research in this direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative questions derived from 182,330 real-world chatbot conversations. Experiments show that existing methods either struggle to reason effectively or incur prohibitive computational costs, underscoring the need for new approaches capable of extracting collective insights from large-scale conversational data.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 24.0/100  
**Sentiment Score:** 52.9/100

**Justification:** High innovation indicators (score: 30); Strong impact potential (score: 24); Contains key LLM terms (bonus: 10)

## Keywords

aggregative, collective, conversational, insights, interactions, large, aggregative question, answering, approaches, chatbot

## Links

- [Paper URL](https://arxiv.org/abs/2505.23765)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
