# Revisiting Overthinking in Long Chain-of-Thought from the Perspective of Self-Doubt

**Authors:** Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Dacheng Tao

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 35.8/100

## Abstract

arXiv:2505.23480v1 Announce Type: new 
Abstract: Reasoning Large Language Models (RLLMs) have demonstrated impressive performance on complex tasks, largely due to the adoption of Long Chain-of-Thought (Long CoT) reasoning. However, they often exhibit overthinking -- performing unnecessary reasoning steps even after arriving at the correct answer. Prior work has largely focused on qualitative analyses of overthinking through sample-based observations of long CoTs. In contrast, we present a quantitative analysis of overthinking from the perspective of self-doubt, characterized by excessive token usage devoted to re-verifying already-correct answer. We find that self-doubt significantly contributes to overthinking. In response, we introduce a simple and effective prompting method to reduce the model's over-reliance on input questions, thereby avoiding self-doubt. Specifically, we first prompt the model to question the validity of the input question, and then respond concisely based on the outcome of that evaluation. Experiments on three mathematical reasoning tasks and four datasets with missing premises demonstrate that our method substantially reduces answer length and yields significant improvements across nearly all datasets upon 4 widely-used RLLMs. Further analysis demonstrates that our method effectively minimizes the number of reasoning steps and reduces self-doubt.

## Analysis

**Innovation Score:** 20.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 53.9/100

**Justification:** Contains key LLM terms (bonus: 10)

## Keywords

doubt, overthinking, reasoning, self, self doubt, long, answer, method, analysis, based

## Links

- [Paper URL](https://arxiv.org/abs/2505.23480)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
