# C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation

**Authors:** Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 38.3/100

## Abstract

arXiv:2412.04947v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data contamination due to the lack of access to proprietary training data. To address this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark featuring systematic contamination prevention. C$^2$LEVA firstly offers a holistic evaluation encompassing 22 tasks, each targeting a specific application or ability of LLMs, and secondly a trustworthy assessment due to our contamination-free tasks, ensured by a systematic contamination prevention strategy that fully automates test data renewal and enforces data protection during benchmark data release. Our large-scale evaluation of 15 open-source and proprietary models demonstrates the effectiveness of C$^2$LEVA.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 24.0/100  
**Sentiment Score:** 54.1/100

**Justification:** High innovation indicators (score: 30); Strong impact potential (score: 24); Contains key LLM terms (bonus: 10)

## Keywords

contamination, data, evaluation, leva, benchmark, comprehensive, contamination free, contamination prevention, free, language

## Links

- [Paper URL](https://arxiv.org/abs/2412.04947)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
