# Context Robust Knowledge Editing for Language Models

**Authors:** Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 37.3/100

## Abstract

arXiv:2505.23026v1 Announce Type: new 
Abstract: Knowledge editing (KE) methods offer an efficient way to modify knowledge in large language models. Current KE evaluations typically assess editing success by considering only the edited knowledge without any preceding contexts. In real-world applications, however, preceding contexts often trigger the retrieval of the original knowledge and undermine the intended edit. To address this issue, we develop CHED -- a benchmark designed to evaluate the context robustness of KE methods. Evaluations on CHED show that they often fail when preceding contexts are present. To mitigate this shortcoming, we introduce CoRE, a KE method designed to strengthen context robustness by minimizing context-sensitive variance in hidden states of the model for edited knowledge. This method not only improves the editing success rate in situations where a preceding context is present but also preserves the overall capabilities of the model. We provide an in-depth analysis of the differing impacts of preceding contexts when introduced as user utterances versus assistant responses, and we dissect attention-score patterns to assess how specific tokens influence editing success.

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 52.5/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)

## Keywords

knowledge, context, editing, preceding, contexts, ke, preceding contexts, editing success, success, assess

## Links

- [Paper URL](https://arxiv.org/abs/2505.23026)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
