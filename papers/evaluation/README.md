# Evaluation Papers

This directory contains papers related to evaluation in large language models and AI.

## Papers (16 total)

### Can Large Language Models Match the Conclusions of Systematic Reviews?

**Score:** 92.0 | **Published:** 2025-05-30 | **Authors:** Christopher Polzak, Alejandro Lozano, Min Woo Sun, James Burgess, Yuhui Zhang, Kevin Wu, Serena Yeung-Levy

arXiv:2505.22787v1 Announce Type: new 
Abstract: Systematic reviews (SR), in which experts summarize and analyze evidence across individual studies to provide insights on a specialized topic, are a co...

[📄 Full Paper](https://arxiv.org/abs/2505.22787) | [📝 Analysis](71d4f123cc5164cd589c7f8354936f1d.md)

---

### FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models

**Score:** 90.0 | **Published:** 2025-06-04 | **Authors:** Yan Gao, Massimo Roberto Scamarcia, Javier Fernandez-Marques, Mohammad Naseri, Chong Shen Ng, Dimitris Stripelis, Zexi Li, Tao Shen, Jiamu Bai, Daoyuan Chen, Zikai Zhang, Rui Hu, InSeo Song, Lee KangYoon, Hong Jia, Ting Dang, Junyan Wang, Zheyuan Liu, Daniel Janes Beutel, Lingjuan Lyu, Nicholas D. Lane

arXiv:2506.02961v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved state-of-the-art results across diverse domains, yet their development remains reliant on vast amounts of pu...

[📄 Full Paper](https://arxiv.org/abs/2506.02961) | [📝 Analysis](89836a120af73eb79607849c1f6a0c7e.md)

---

### MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators

**Score:** 88.0 | **Published:** 2025-05-30 | **Authors:** John Mendon\c{c}a, Alon Lavie, Isabel Trancoso

arXiv:2505.22777v1 Announce Type: new 
Abstract: As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a majo...

[📄 Full Paper](https://arxiv.org/abs/2505.22777) | [📝 Analysis](d72fcac8f7812b7b34df451ca768d0bd.md)

---

### ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering

**Score:** 47.3 | **Published:** 2025-05-30 | **Authors:** Jingxuan Wei, Nan Xu, Junnan Zhu, Yanni Hao, Gaowei Wu, Bihui Yu, Lei Wang

arXiv:2505.23242v1 Announce Type: new 
Abstract: Chart question answering (CQA) has become a critical multimodal task for evaluating the reasoning capabilities of vision-language models. While early a...

[📄 Full Paper](https://arxiv.org/abs/2505.23242) | [📝 Analysis](1288293babf173945905e7fc26c06dd1.md)

---

### Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons

**Score:** 40.6 | **Published:** 2025-05-30 | **Authors:** Krithik Vishwanath, Anton Alyakin, Mrigayu Ghosh, Jin Vivian Lee, Daniel Alexander Alber, Karl L. Sangwon, Douglas Kondziolka, Eric Karl Oermann

arXiv:2505.23477v1 Announce Type: new 
Abstract: The Congress of Neurological Surgeons Self-Assessment for Neurological Surgeons (CNS-SANS) questions are widely used by neurosurgical residents to prep...

[📄 Full Paper](https://arxiv.org/abs/2505.23477) | [📝 Analysis](3bf527375cbcb8beb366dadf536eb6b8.md)

---

### LLM Agents for Bargaining with Utility-based Feedback

**Score:** 40.3 | **Published:** 2025-05-30 | **Authors:** Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim

arXiv:2505.22998v1 Announce Type: new 
Abstract: Bargaining, a critical aspect of real-world interactions, presents challenges for large language models (LLMs) due to limitations in strategic depth an...

[📄 Full Paper](https://arxiv.org/abs/2505.22998) | [📝 Analysis](cb1f10d35a07e9d874be32499596b216.md)

---

### OmniEarth-Bench: Towards Holistic Evaluation of Earth's Six Spheres and Cross-Spheres Interactions with Multimodal Observational Earth Data

**Score:** 39.2 | **Published:** 2025-05-30 | **Authors:** Fengxiang Wang, Mingshuo Chen, Xuming He, YiFan Zhang, Feng Liu, Zijie Guo, Zhenghao Hu, Jiong Wang, Jingyi Xu, Zhangrui Li, Fenghua Ling, Ben Fei, Weijia Li, Long Lan, Wenjing Yang, Wenlong Zhang, Lei Bai

arXiv:2505.23522v1 Announce Type: cross 
Abstract: Existing benchmarks for Earth science multimodal learning exhibit critical limitations in systematic coverage of geosystem components and cross-spher...

[📄 Full Paper](https://arxiv.org/abs/2505.23522) | [📝 Analysis](c98101575103a613543c6530938cd9de.md)

---

### C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

arXiv:2412.04947v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data c...

[📄 Full Paper](https://arxiv.org/abs/2412.04947) | [📝 Analysis](23a7d79f0883b5464ed85cf3c145c238.md)

---

### MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Hao Lu, Yanchi Gu, Haoyuan Huang, Yulin Zhou, Ningxin Zhu, Chen Li

arXiv:2505.23229v1 Announce Type: new 
Abstract: The integration of Monte Carlo Tree Search (MCTS) with Large Language Models (LLMs) has demonstrated significant success in structured, problem-oriente...

[📄 Full Paper](https://arxiv.org/abs/2505.23229) | [📝 Analysis](4d5762e5f46db9c4dbdd96365274e61d.md)

---

### EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Wanghan Xu, Xiangyu Zhao, Yuhao Zhou, Xiaoyu Yue, Ben Fei, Fenghua Ling, Wenlong Zhang, Lei Bai

arXiv:2505.17139v2 Announce Type: replace 
Abstract: Advancements in Large Language Models (LLMs) drive interest in scientific applications, necessitating specialized benchmarks such as Earth science....

[📄 Full Paper](https://arxiv.org/abs/2505.17139) | [📝 Analysis](6fa92b4fe8ef1812d06829c7facf0caa.md)

---

### Context Robust Knowledge Editing for Language Models

**Score:** 37.3 | **Published:** 2025-05-30 | **Authors:** Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo

arXiv:2505.23026v1 Announce Type: new 
Abstract: Knowledge editing (KE) methods offer an efficient way to modify knowledge in large language models. Current KE evaluations typically assess editing suc...

[📄 Full Paper](https://arxiv.org/abs/2505.23026) | [📝 Analysis](1acab1d5ede7274ee5e632e6ee25fbeb.md)

---

### Two Is Better Than One: Rotations Scale LoRAs

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang

arXiv:2505.23184v1 Announce Type: new 
Abstract: Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates large language models (LLMs) to efficiently adapt to diverse tasks. Howev...

[📄 Full Paper](https://arxiv.org/abs/2505.23184) | [📝 Analysis](a5b48ab9c14ed00df559f0441cf36789.md)

---

### Augment or Not? A Comparative Study of Pure and Augmented Large Language Model Recommenders

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Wei-Hsiang Huang, Chen-Wei Ke, Wei-Ning Chiu, Yu-Xuan Su, Chun-Chun Yang, Chieh-Yuan Cheng, Yun-Nung Chen, Pu-Jen Cheng

arXiv:2505.23053v1 Announce Type: cross 
Abstract: Large language models (LLMs) have introduced new paradigms for recommender systems by enabling richer semantic understanding and incorporating implic...

[📄 Full Paper](https://arxiv.org/abs/2505.23053) | [📝 Analysis](7d6fe3bdba7d5e91868aecf26b3cb40f.md)

---

### ScEdit: Script-based Assessment of Knowledge Editing

**Score:** 36.2 | **Published:** 2025-05-30 | **Authors:** Xinye Li, Zunwen Zheng, Qian Zhang, Dekai Zhuang, Jiabao Kang, Liyan Xu, Qingbin Liu, Xi Chen, Zhiying Tu, Dianhui Chu, Dianbo Sui

arXiv:2505.23291v1 Announce Type: new 
Abstract: Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editin...

[📄 Full Paper](https://arxiv.org/abs/2505.23291) | [📝 Analysis](e317e3d8e9068956a0ac77ac3af0b380.md)

---

### LLMs for Argument Mining: Detection, Extraction, and Relationship Classification of pre-defined Arguments in Online Comments

**Score:** 35.9 | **Published:** 2025-05-30 | **Authors:** Matteo Guida, Yulia Otmakhova, Eduard Hovy, Lea Frermann

arXiv:2505.22956v1 Announce Type: new 
Abstract: Automated large-scale analysis of public discussions around contested issues like abortion requires detecting and understanding the use of arguments. W...

[📄 Full Paper](https://arxiv.org/abs/2505.22956) | [📝 Analysis](89538cd7659bba74a15aa553f8b0e8d3.md)

---

### NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables

**Score:** 35.7 | **Published:** 2025-05-30 | **Authors:** Lanrui Wang, Mingyu Zheng, Hongyin Tang, Zheng Lin, Yanan Cao, Jingang Wang, Xunliang Cai, Weiping Wang

arXiv:2504.06560v2 Announce Type: replace 
Abstract: Processing structured tabular data, particularly large and lengthy tables, constitutes a fundamental yet challenging task for large language models...

[📄 Full Paper](https://arxiv.org/abs/2504.06560) | [📝 Analysis](787f4b4374ea95f22732eefe21e1582d.md)

---


*Last updated: 2025-06-04 09:29:15 UTC*
