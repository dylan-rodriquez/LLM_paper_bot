# Evaluation Papers

This directory contains papers related to evaluation in large language models and AI.

## Papers (18 total)

### Can Large Language Models Match the Conclusions of Systematic Reviews?

**Score:** 92.0 | **Published:** 2025-05-30 | **Authors:** Christopher Polzak, Alejandro Lozano, Min Woo Sun, James Burgess, Yuhui Zhang, Kevin Wu, Serena Yeung-Levy

arXiv:2505.22787v1 Announce Type: new 
Abstract: Systematic reviews (SR), in which experts summarize and analyze evidence across individual studies to provide insights on a specialized topic, are a co...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22787) | [ğŸ“ Analysis](71d4f123cc5164cd589c7f8354936f1d.md)

---

### Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework

**Score:** 92.0 | **Published:** 2025-06-02 | **Authors:** Aakash Sen Sharma, Debdeep Sanyal, Priyansh Srivastava, Sundar Atreya H., Shirish Karande, Mohan Kankanhalli, Murari Mandal

arXiv:2505.23788v1 Announce Type: new 
Abstract: Large language models (LLMs) commonly risk copyright infringement by reproducing protected content verbatim or with insufficient transformative modific...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23788) | [ğŸ“ Analysis](c6874c80f4d6cc2da0d58f42a9a39c4d.md)

---

### MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks

**Score:** 92.0 | **Published:** 2025-06-02 | **Authors:** Suhana Bedi, Hejie Cui, Miguel Fuentes, Alyssa Unell, Michael Wornow, Juan M. Banda, Nikesh Kotecha, Timothy Keyes, Yifan Mai, Mert Oez, Hao Qiu, Shrey Jain, Leonardo Schettini, Mehr Kashyap, Jason Alan Fries, Akshay Swaminathan, Philip Chung, Fateme Nateghi, Asad Aali, Ashwin Nayak, Shivam Vedak, Sneha S. Jain, Birju Patel, Oluseyi Fayanju, Shreya Shah, Ethan Goh, Dong-han Yao, Brian Soetikno, Eduardo Reis, Sergios Gatidis, Vasu Divi, Robson Capasso, Rachna Saralkar, Chia-Chun Chiang, Jenelle Jindal, Tho Pham, Faraz Ghoddusi, Steven Lin, Albert S. Chiou, Christy Hong, Mohana Roy, Michael F. Gensheimer, Hinesh Patel, Kevin Schulman, Dev Dash, Danton Char, Lance Downing, Francois Grolleau, Kameron Black, Bethel Mieso, Aydin Zahedivash, Wen-wai Yim, Harshita Sharma, Tony Lee, Hannah Kirsch, Jennifer Lee, Nerissa Ambers, Carlene Lugtu, Aditya Sharma, Bilal Mawji, Alex Alekseyev, Vicky Zhou, Vikas Kakkar, Jarrod Helzer, Anurang Revri, Yair Bannett, Roxana Daneshjou, Jonathan Chen, Emily Alsentzer, Keith Morse, Nirmal Ravi, Nima Aghaeepour, Vanessa Kennedy, Akshay Chaudhari, Thomas Wang, Sanmi Koyejo, Matthew P. Lungren, Eric Horvitz, Percy Liang, Mike Pfeffer, Nigam H. Shah

arXiv:2505.23802v1 Announce Type: new 
Abstract: While large language models (LLMs) achieve near-perfect scores on medical licensing exams, these evaluations inadequately reflect the complexity and di...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23802) | [ğŸ“ Analysis](008b8664607dc291796d11e7a2e20835.md)

---

### Large Language Models Often Know When They Are Being Evaluated

**Score:** 90.0 | **Published:** 2025-06-02 | **Authors:** Joe Needham, Giles Edkins, Govind Pimpale, Henning Bartsch, Marius Hobbhahn

arXiv:2505.23836v1 Announce Type: new 
Abstract: If AI models can detect when they are being evaluated, the effectiveness of evaluations might be compromised. For example, models could have systematic...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23836) | [ğŸ“ Analysis](7f7897c1b06672cf52e73ea842a58bb9.md)

---

### MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators

**Score:** 88.0 | **Published:** 2025-05-30 | **Authors:** John Mendon\c{c}a, Alon Lavie, Isabel Trancoso

arXiv:2505.22777v1 Announce Type: new 
Abstract: As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a majo...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22777) | [ğŸ“ Analysis](d72fcac8f7812b7b34df451ca768d0bd.md)

---

### ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering

**Score:** 47.3 | **Published:** 2025-05-30 | **Authors:** Jingxuan Wei, Nan Xu, Junnan Zhu, Yanni Hao, Gaowei Wu, Bihui Yu, Lei Wang

arXiv:2505.23242v1 Announce Type: new 
Abstract: Chart question answering (CQA) has become a critical multimodal task for evaluating the reasoning capabilities of vision-language models. While early a...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23242) | [ğŸ“ Analysis](1288293babf173945905e7fc26c06dd1.md)

---

### Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons

**Score:** 40.6 | **Published:** 2025-05-30 | **Authors:** Krithik Vishwanath, Anton Alyakin, Mrigayu Ghosh, Jin Vivian Lee, Daniel Alexander Alber, Karl L. Sangwon, Douglas Kondziolka, Eric Karl Oermann

arXiv:2505.23477v1 Announce Type: new 
Abstract: The Congress of Neurological Surgeons Self-Assessment for Neurological Surgeons (CNS-SANS) questions are widely used by neurosurgical residents to prep...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23477) | [ğŸ“ Analysis](3bf527375cbcb8beb366dadf536eb6b8.md)

---

### LLM Agents for Bargaining with Utility-based Feedback

**Score:** 40.3 | **Published:** 2025-05-30 | **Authors:** Jihwan Oh, Murad Aghazada, Se-Young Yun, Taehyeon Kim

arXiv:2505.22998v1 Announce Type: new 
Abstract: Bargaining, a critical aspect of real-world interactions, presents challenges for large language models (LLMs) due to limitations in strategic depth an...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22998) | [ğŸ“ Analysis](cb1f10d35a07e9d874be32499596b216.md)

---

### OmniEarth-Bench: Towards Holistic Evaluation of Earth's Six Spheres and Cross-Spheres Interactions with Multimodal Observational Earth Data

**Score:** 39.2 | **Published:** 2025-05-30 | **Authors:** Fengxiang Wang, Mingshuo Chen, Xuming He, YiFan Zhang, Feng Liu, Zijie Guo, Zhenghao Hu, Jiong Wang, Jingyi Xu, Zhangrui Li, Fenghua Ling, Ben Fei, Weijia Li, Long Lan, Wenjing Yang, Wenlong Zhang, Lei Bai

arXiv:2505.23522v1 Announce Type: cross 
Abstract: Existing benchmarks for Earth science multimodal learning exhibit critical limitations in systematic coverage of geosystem components and cross-spher...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23522) | [ğŸ“ Analysis](c98101575103a613543c6530938cd9de.md)

---

### C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng, Ka Wai Liu, Michael R. Lyu, Liwei Wang

arXiv:2412.04947v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data c...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2412.04947) | [ğŸ“ Analysis](23a7d79f0883b5464ed85cf3c145c238.md)

---

### MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Hao Lu, Yanchi Gu, Haoyuan Huang, Yulin Zhou, Ningxin Zhu, Chen Li

arXiv:2505.23229v1 Announce Type: new 
Abstract: The integration of Monte Carlo Tree Search (MCTS) with Large Language Models (LLMs) has demonstrated significant success in structured, problem-oriente...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23229) | [ğŸ“ Analysis](4d5762e5f46db9c4dbdd96365274e61d.md)

---

### EarthSE: A Benchmark Evaluating Earth Scientific Exploration Capability for Large Language Models

**Score:** 38.3 | **Published:** 2025-05-30 | **Authors:** Wanghan Xu, Xiangyu Zhao, Yuhao Zhou, Xiaoyu Yue, Ben Fei, Fenghua Ling, Wenlong Zhang, Lei Bai

arXiv:2505.17139v2 Announce Type: replace 
Abstract: Advancements in Large Language Models (LLMs) drive interest in scientific applications, necessitating specialized benchmarks such as Earth science....

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.17139) | [ğŸ“ Analysis](6fa92b4fe8ef1812d06829c7facf0caa.md)

---

### Context Robust Knowledge Editing for Language Models

**Score:** 37.3 | **Published:** 2025-05-30 | **Authors:** Haewon Park, Gyubin Choi, Minjun Kim, Yohan Jo

arXiv:2505.23026v1 Announce Type: new 
Abstract: Knowledge editing (KE) methods offer an efficient way to modify knowledge in large language models. Current KE evaluations typically assess editing suc...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23026) | [ğŸ“ Analysis](1acab1d5ede7274ee5e632e6ee25fbeb.md)

---

### Two Is Better Than One: Rotations Scale LoRAs

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Hongcan Guo, Guoshun Nan, Yuan Yang, Diyang Zhang, Haotian Li, Zhican Chen, Qinchuan Zhou, Yuhan Ran, Xinye Cao, Sicong Leng, Xiaofeng Tao, Xudong Jiang

arXiv:2505.23184v1 Announce Type: new 
Abstract: Scaling Low-Rank Adaptation (LoRA)-based Mixture-of-Experts (MoE) facilitates large language models (LLMs) to efficiently adapt to diverse tasks. Howev...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23184) | [ğŸ“ Analysis](a5b48ab9c14ed00df559f0441cf36789.md)

---

### Augment or Not? A Comparative Study of Pure and Augmented Large Language Model Recommenders

**Score:** 36.4 | **Published:** 2025-05-30 | **Authors:** Wei-Hsiang Huang, Chen-Wei Ke, Wei-Ning Chiu, Yu-Xuan Su, Chun-Chun Yang, Chieh-Yuan Cheng, Yun-Nung Chen, Pu-Jen Cheng

arXiv:2505.23053v1 Announce Type: cross 
Abstract: Large language models (LLMs) have introduced new paradigms for recommender systems by enabling richer semantic understanding and incorporating implic...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23053) | [ğŸ“ Analysis](7d6fe3bdba7d5e91868aecf26b3cb40f.md)

---

### ScEdit: Script-based Assessment of Knowledge Editing

**Score:** 36.2 | **Published:** 2025-05-30 | **Authors:** Xinye Li, Zunwen Zheng, Qian Zhang, Dekai Zhuang, Jiabao Kang, Liyan Xu, Qingbin Liu, Xi Chen, Zhiying Tu, Dianhui Chu, Dianbo Sui

arXiv:2505.23291v1 Announce Type: new 
Abstract: Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editin...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.23291) | [ğŸ“ Analysis](e317e3d8e9068956a0ac77ac3af0b380.md)

---

### LLMs for Argument Mining: Detection, Extraction, and Relationship Classification of pre-defined Arguments in Online Comments

**Score:** 35.9 | **Published:** 2025-05-30 | **Authors:** Matteo Guida, Yulia Otmakhova, Eduard Hovy, Lea Frermann

arXiv:2505.22956v1 Announce Type: new 
Abstract: Automated large-scale analysis of public discussions around contested issues like abortion requires detecting and understanding the use of arguments. W...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2505.22956) | [ğŸ“ Analysis](89538cd7659bba74a15aa553f8b0e8d3.md)

---

### NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables

**Score:** 35.7 | **Published:** 2025-05-30 | **Authors:** Lanrui Wang, Mingyu Zheng, Hongyin Tang, Zheng Lin, Yanan Cao, Jingang Wang, Xunliang Cai, Weiping Wang

arXiv:2504.06560v2 Announce Type: replace 
Abstract: Processing structured tabular data, particularly large and lengthy tables, constitutes a fundamental yet challenging task for large language models...

[ğŸ“„ Full Paper](https://arxiv.org/abs/2504.06560) | [ğŸ“ Analysis](787f4b4374ea95f22732eefe21e1582d.md)

---


*Last updated: 2025-06-02 09:29:50 UTC*
