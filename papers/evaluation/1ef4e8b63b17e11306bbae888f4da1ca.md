# Measuring Participant Contributions in Decentralized Federated Learning

**Authors:** Honoka Anada, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki

**Published:** 2025-05-31 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 85.0/100

## Abstract

arXiv:2505.23246v1 Announce Type: new 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train models without sharing their data. Measuring participant contributions in FL is crucial for incentivizing clients and ensuring transparency. While various methods have been proposed for contribution measurement, they are designed exclusively for centralized federated learning (CFL), where a central server collects and aggregates client models, along with evaluating their contributions. Meanwhile, decentralized federated learning (DFL), in which clients exchange models directly without a central server, has gained significant attention for mitigating communication bottlenecks and eliminating a single point of failure. However, applying existing contribution measurement methods to DFL is challenging due to the presence of multiple global models and the absence of a central server. In this study, we present novel methodologies for measuring participant contributions in DFL. We first propose DFL-Shapley, an extension of the Shapley value tailored for DFL, adapting this widely used CFL metric to decentralized settings. Given the impracticality of computing the ideal DFL-Shapley in real-world systems, we introduce DFL-MR, a computable approximation that estimates overall contributions by accumulating round-wise Shapley values. We evaluate DFL-Shapley and DFL-MR across various FL scenarios and compare them with existing CFL metrics. The experimental results confirm DFL-Shapley as a valid ground-truth metric and demonstrate DFL-MR's proximity to DFL-Shapley across various settings, highlighting their effectiveness as contribution metrics in DFL.

## Analysis

**Innovation Score:** 72.0/100
**Impact Score:** 75.0/100  
**Sentiment Score:** 80.0/100

**Justification:** The paper addresses a crucial gap in federated learning by tackling contribution measurement in the decentralized setting, which is a growing area of research. The problem is well-defined and the motivation is clear. While the abstract doesn't detail the specific methodologies, the identification of the challenge posed by the lack of a central server suggests a thoughtful approach. The potential for incentivizing participation in DFL is significant, making this work relevant and likely to be well-received.

## Keywords

dfl, shapley, contributions, dfl shapley, federated, federated learning, learning, models, central, central server

## Links

- [Paper URL](https://arxiv.org/abs/2505.23246)

---
*Auto-generated on 2025-05-31 09:25:12 UTC*
