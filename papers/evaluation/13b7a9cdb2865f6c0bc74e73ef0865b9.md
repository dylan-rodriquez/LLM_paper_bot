# Fact-Controlled Diagnosis of Hallucinations in Medical Text Summarization

**Authors:** Suhas BN, Han-Chin Shing, Lei Xu, Mitch Strong, Jon Burnsky, Jessica Ofor, Jordan R. Mason, Susan Chen, Sundararajan Srinivasan, Chaitanya Shivade, Jack Moriarty, Joseph Paul Cohen

**Published:** 2025-06-03 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 92.0/100

## Abstract

arXiv:2506.00448v1 Announce Type: new 
Abstract: Hallucinations in large language models (LLMs) during summarization of patient-clinician dialogues pose significant risks to patient care and clinical decision-making. However, the phenomenon remains understudied in the clinical domain, with uncertainty surrounding the applicability of general-domain hallucination detectors. The rarity and randomness of hallucinations further complicate their investigation. In this paper, we conduct an evaluation of hallucination detection methods in the medical domain, and construct two datasets for the purpose: A fact-controlled Leave-N-out dataset -- generated by systematically removing facts from source dialogues to induce hallucinated content in summaries; and a natural hallucination dataset -- arising organically during LLM-based medical summarization. We show that general-domain detectors struggle to detect clinical hallucinations, and that performance on fact-controlled hallucinations does not reliably predict effectiveness on natural hallucinations. We then develop fact-based approaches that count hallucinations, offering explainability not available with existing methods. Notably, our LLM-based detectors, which we developed using fact-controlled hallucinations, generalize well to detecting real-world clinical hallucinations. This research contributes a suite of specialized metrics supported by expert-annotated datasets to advance faithful clinical summarization systems.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 85.0/100

**Justification:** This paper tackles a crucial problem – hallucinations in medical LLM summarization – which has high stakes for patient safety. The creation of both fact-controlled and natural hallucination datasets is a significant contribution, addressing a key limitation in the field. While the methods for dataset creation seem sound, the abstract hints at findings that general detectors struggle, suggesting the core innovation lies more in the datasets than a novel detection method itself, but the evaluation is still valuable.

## Keywords

hallucinations, clinical, fact, controlled, domain, fact controlled, summarization, based, detectors, hallucination

## Links

- [Paper URL](https://arxiv.org/abs/2506.00448)

---
*Auto-generated on 2025-06-03 09:29:41 UTC*
