# MuLoCo: Muon is a practical inner optimizer for DiLoCo

**Authors:** Benjamin Th\'erien, Xiaolong Huang, Irina Rish, Eugene Belilovsky

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.LG

**Significance Score:** 38.9/100

## Abstract

arXiv:2505.23725v1 Announce Type: new 
Abstract: DiLoCo is a powerful framework for training large language models (LLMs) under networking constraints with advantages for increasing parallelism and accelerator utilization in data center settings. Despite significantly reducing communication frequency, however, DiLoCo's communication steps still involve all-reducing a complete copy of the model's parameters. While existing works have explored ways to reduce communication in DiLoCo, the role of error feedback accumulators and the effect of the inner-optimizer on compressibility remain under-explored. In this work, we investigate the effectiveness of standard compression methods including Top-k sparsification and quantization for reducing the communication overhead of DiLoCo when paired with two local optimizers (AdamW and Muon). Our experiments pre-training decoder-only transformer language models (LMs) reveal that leveraging Muon as the inner optimizer for DiLoCo along with an error-feedback accumulator allows to aggressively compress the communicated delta to 2-bits with next to no performance degradation. Crucially, MuLoCo (Muon inner optimizer DiLoCo) significantly outperforms DiLoCo while communicating 8X less and having identical memory complexity.

## Analysis

**Innovation Score:** 20.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 50.8/100

**Justification:** Contains key LLM terms (bonus: 15)

## Keywords

diloco, communication, inner, inner optimizer, muon, optimizer, optimizer diloco, reducing, error, error feedback

## Links

- [Paper URL](https://arxiv.org/abs/2505.23725)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
