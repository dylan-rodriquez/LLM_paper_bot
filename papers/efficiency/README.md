# Efficiency Papers

This directory contains papers related to efficiency in large language models and AI.

## Papers (7 total)

### Mustafar: Promoting Unstructured Sparsity for KV Cache Pruning in LLM Inference

**Score:** 88.0 | **Published:** 2025-05-31 | **Authors:** Donghyeon Joo, Helya Hosseini, Ramyad Hadidi, Bahar Asgari

arXiv:2505.22913v1 Announce Type: new 
Abstract: We demonstrate that unstructured sparsity significantly improves KV cache compression for LLMs, enabling sparsity levels up to 70% without compromising...

[📄 Full Paper](https://arxiv.org/abs/2505.22913) | [📝 Analysis](fdce4c7af13e09d4dcdef3275ac911d6.md)

---

### Automated Modeling Method for Pathloss Model Discovery

**Score:** 85.0 | **Published:** 2025-05-31 | **Authors:** Ahmad Anaqreh, Shih-Kai Chou, Mihael Mohor\v{c}i\v{c}, Carolina Fortuna

arXiv:2505.23383v1 Announce Type: new 
Abstract: Modeling propagation is the cornerstone for designing and optimizing next-generation wireless systems, with a particular emphasis on 5G and beyond era....

[📄 Full Paper](https://arxiv.org/abs/2505.23383) | [📝 Analysis](9cc79b564d8d11fb949f959ebf76b2bd.md)

---

### DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration

**Score:** 45.2 | **Published:** 2025-05-30 | **Authors:** Tianteng Gu, Bei Liu, Bo Xiao, Ke Zeng, Jiacheng Liu, Yanmin Qian

arXiv:2505.23049v1 Announce Type: cross 
Abstract: Pruning is a widely used technique to compress large language models (LLMs) by removing unimportant weights, but it often suffers from significant pe...

[📄 Full Paper](https://arxiv.org/abs/2505.23049) | [📝 Analysis](3685d117c5da31e3837f8bffcdfa252d.md)

---

### MuLoCo: Muon is a practical inner optimizer for DiLoCo

**Score:** 38.9 | **Published:** 2025-05-30 | **Authors:** Benjamin Th\'erien, Xiaolong Huang, Irina Rish, Eugene Belilovsky

arXiv:2505.23725v1 Announce Type: new 
Abstract: DiLoCo is a powerful framework for training large language models (LLMs) under networking constraints with advantages for increasing parallelism and ac...

[📄 Full Paper](https://arxiv.org/abs/2505.23725) | [📝 Analysis](d7ca63bf2a24d9c79ad827785dcf6592.md)

---

### Token Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?

**Score:** 37.0 | **Published:** 2025-05-30 | **Authors:** Zichen Wen, Yifeng Gao, Weijia Li, Conghui He, Linfeng Zhang

arXiv:2502.11501v2 Announce Type: replace 
Abstract: Multimodal large language models (MLLMs) have shown remarkable performance for cross-modal understanding and generation, yet still suffer from seve...

[📄 Full Paper](https://arxiv.org/abs/2502.11501) | [📝 Analysis](e1f5572d1b8f8047bc593c39e9661f8f.md)

---

### SLiM: One-shot Quantization and Sparsity with Low-rank Approximation for LLM Weight Compression

**Score:** 35.2 | **Published:** 2025-05-30 | **Authors:** Mohammad Mozaffari, Amir Yazdanbakhsh, Maryam Mehri Dehnavi

arXiv:2410.09615v3 Announce Type: replace-cross 
Abstract: Conventional model compression techniques for LLMs address high memory consumption and slow inference challenges but typically require comput...

[📄 Full Paper](https://arxiv.org/abs/2410.09615) | [📝 Analysis](faea11ea11f79fe7d5a489ac34444939.md)

---

### Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems

**Score:** 35.0 | **Published:** 2025-05-30 | **Authors:** Xu Shen, Yixin Liu, Yiwei Dai, Yili Wang, Rui Miao, Yue Tan, Shirui Pan, Xin Wang

arXiv:2505.23352v1 Announce Type: cross 
Abstract: The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically sha...

[📄 Full Paper](https://arxiv.org/abs/2505.23352) | [📝 Analysis](ccad0f4d91e78674aa8e765d63bded10.md)

---


*Last updated: 2025-05-31 09:25:12 UTC*
