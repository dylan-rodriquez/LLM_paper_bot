{
  "papers": [
    {
      "title": "Query Routing for Retrieval-Augmented Language Models",
      "authors": [
        "Jiarui Zhang, Xiangyu Liu, Yong Hu, Chaoyue Niu, Fan Wu, Guihai Chen"
      ],
      "abstract": "arXiv:2505.23052v1 Announce Type: new \nAbstract: Retrieval-Augmented Generation (RAG) significantly improves the performance of Large Language Models (LLMs) on knowledge-intensive tasks. However, varying response quality across LLMs under RAG necessitates intelligent routing mechanisms, which select the most suitable model for each query from multiple retrieval-augmented LLMs via a dedicated router model. We observe that external documents dynamically affect LLMs' ability to answer queries, while existing routing methods, which rely on static parametric knowledge representations, exhibit suboptimal performance in RAG scenarios. To address this, we formally define the new retrieval-augmented LLM routing problem, incorporating the influence of retrieved documents into the routing framework. We propose RAGRouter, a RAG-aware routing design, which leverages document embeddings and RAG capability embeddings with contrastive learning to capture knowledge representation shifts and enable informed routing decisions. Extensive experiments on diverse knowledge-intensive tasks and retrieval settings show that RAGRouter outperforms the best individual LLM by 3.61% on average and existing routing methods by 3.29%-9.33%. With an extended score-threshold-based mechanism, it also achieves strong performance-efficiency trade-offs under low-latency constraints.",
      "url": "https://arxiv.org/abs/2505.23052",
      "published_date": "2025-05-30T00:00:00",
      "source": "arXiv RSS",
      "categories": [
        "cs.CL"
      ],
      "significance_score": 37.75,
      "innovation_score": 30,
      "impact_score": 16,
      "sentiment_score": 55.0,
      "keywords": [
        "routing",
        "rag",
        "retrieval",
        "augmented",
        "knowledge",
        "llms",
        "retrieval augmented",
        "performance",
        "documents",
        "embeddings"
      ],
      "subject_classification": "knowledge",
      "justification": "High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)",
      "paper_id": "12075bcfe291ba6a0dc7d470f18820d7"
    },
    {
      "title": "ParamMute: Suppressing Knowledge-Critical FFNs for Faithful Retrieval-Augmented Generation",
      "authors": [
        "Pengcheng Huang, Zhenghao Liu, Yukun Yan, Haiyan Zhao, Xiaoyuan Yi, Hao Chen, Zhiyuan Liu, Maosong Sun, Tong Xiao, Ge Yu, Chenyan Xiong"
      ],
      "abstract": "arXiv:2502.15543v2 Announce Type: replace \nAbstract: Large language models (LLMs) integrated with retrieval-augmented generation (RAG) have improved factuality by grounding outputs in external evidence. However, they remain susceptible to unfaithful generation, where outputs contradict retrieved context despite its relevance and accuracy. Existing approaches aiming to improve faithfulness primarily focus on enhancing the utilization of external context, but often overlook the persistent influence of internal parametric knowledge during generation. In this work, we investigate the internal mechanisms behind unfaithful generation and identify a subset of mid-to-deep feed-forward networks (FFNs) that are disproportionately activated in such cases. Building on this insight, we propose Parametric Knowledge Muting through FFN Suppression (ParamMute), a framework that improves contextual faithfulness by suppressing the activation of unfaithfulness-associated FFNs and calibrating the model toward retrieved knowledge. To evaluate our approach, we introduce CoFaithfulQA, a benchmark specifically designed to evaluate faithfulness in scenarios where internal knowledge conflicts with accurate external evidence. Experimental results show that ParamMute significantly enhances faithfulness across both CoFaithfulQA and the established ConFiQA benchmark, achieving substantial reductions in reliance on parametric memory. These findings underscore the importance of mitigating internal knowledge dominance and provide a new direction for improving LLM trustworthiness in RAG. All code will be released via GitHub.",
      "url": "https://arxiv.org/abs/2502.15543",
      "published_date": "2025-05-30T00:00:00",
      "source": "arXiv RSS",
      "categories": [
        "cs.CL"
      ],
      "significance_score": 37.13,
      "innovation_score": 20,
      "impact_score": 24,
      "sentiment_score": 56.9,
      "keywords": [
        "knowledge",
        "generation",
        "faithfulness",
        "internal",
        "external",
        "ffns",
        "parametric",
        "parammute",
        "augmented",
        "augmented generation"
      ],
      "subject_classification": "knowledge",
      "justification": "Strong impact potential (score: 24); Contains key LLM terms (bonus: 10)",
      "paper_id": "cffea00d2a82804de78275092b181c5f"
    },
    {
      "title": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora",
      "authors": [
        "Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song"
      ],
      "abstract": "arXiv:2505.23628v1 Announce Type: new \nAbstract: We present AutoSchemaKG, a framework for fully autonomous knowledge graph construction that eliminates the need for predefined schemas. Our system leverages large language models to simultaneously extract knowledge triples and induce comprehensive schemas directly from text, modeling both entities and events while employing conceptualization to organize instances into semantic categories. Processing over 50 million documents, we construct ATLAS (Automated Triple Linking And Schema induction), a family of knowledge graphs with 900+ million nodes and 5.9 billion edges. This approach outperforms state-of-the-art baselines on multi-hop QA tasks and enhances LLM factuality. Notably, our schema induction achieves 95\\% semantic alignment with human-crafted schemas with zero manual intervention, demonstrating that billion-scale knowledge graphs with dynamically induced schemas can effectively complement parametric knowledge in large language models.",
      "url": "https://arxiv.org/abs/2505.23628",
      "published_date": "2025-05-30T00:00:00",
      "source": "arXiv RSS",
      "categories": [
        "cs.CL"
      ],
      "significance_score": 36.57,
      "innovation_score": 30,
      "impact_score": 8,
      "sentiment_score": 52.85,
      "keywords": [
        "knowledge",
        "schemas",
        "induction",
        "schema",
        "schema induction",
        "autonomous",
        "autonomous knowledge",
        "autoschemakg",
        "billion",
        "construction"
      ],
      "subject_classification": "knowledge",
      "justification": "High innovation indicators (score: 30); Contains key LLM terms (bonus: 10)",
      "paper_id": "24ab540388b6d3a902007a535e6de39c"
    },
    {
      "title": "CAIRe: Cultural Attribution of Images by Retrieval-Augmented Evaluation",
      "authors": [
        "Arnav Yayavaram, Siddharth Yayavaram, Simran Khanuja, Michael Saxon, Graham Neubig"
      ],
      "abstract": "arXiv:2506.09109v1 Announce Type: cross \nAbstract: As text-to-image models become increasingly prevalent, ensuring their equitable performance across diverse cultural contexts is critical. Efforts to mitigate cross-cultural biases have been hampered by trade-offs, including a loss in performance, factual inaccuracies, or offensive outputs. Despite widespread recognition of these challenges, an inability to reliably measure these biases has stalled progress. To address this gap, we introduce CAIRe, a novel evaluation metric that assesses the degree of cultural relevance of an image, given a user-defined set of labels. Our framework grounds entities and concepts in the image to a knowledge base and uses factual information to give independent graded judgments for each culture label. On a manually curated dataset of culturally salient but rare items built using language models, CAIRe surpasses all baselines by 28% F1 points. Additionally, we construct two datasets for culturally universal concept, one comprising of T2I-generated outputs and another retrieved from naturally occurring data. CAIRe achieves Pearson's correlations of 0.56 and 0.66 with human ratings on these sets, based on a 5-point Likert scale of cultural relevance. This demonstrates its strong alignment with human judgment across diverse image sources.",
      "url": "https://arxiv.org/abs/2506.09109",
      "published_date": "2025-06-12T00:00:00",
      "source": "arXiv RSS",
      "categories": [
        "cs.CV"
      ],
      "significance_score": 92,
      "innovation_score": 78,
      "impact_score": 88,
      "sentiment_score": 80,
      "keywords": [
        "cultural",
        "caire",
        "image",
        "biases",
        "cross",
        "cultural relevance",
        "culturally",
        "diverse",
        "evaluation",
        "factual"
      ],
      "subject_classification": "knowledge",
      "justification": "This paper tackles a crucial and timely problem \u2013 the evaluation of cultural biases in text-to-image models. The introduction of CAIRe, a retrieval-augmented evaluation metric, appears to be a significant step forward, demonstrated by the substantial F1 score improvement over baselines. The creation of curated datasets further strengthens the work, suggesting a rigorous approach and potential for broader impact within the community.",
      "paper_id": "96e48e18c7e75149cd9774bb8f239d77"
    }
  ],
  "last_updated": "2025-06-12T09:29:11.382253"
}