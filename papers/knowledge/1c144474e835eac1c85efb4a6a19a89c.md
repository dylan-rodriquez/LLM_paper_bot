# ConfQA: Answer Only If You Are Confident

**Authors:** Yin Huang, Yifan Ethan Xu, Kai Sun, Vera Yan, Alicia Sun, Haidar Khan, Jimmy Nguyen, Mohammad Kachuee, Zhaojiang Lin, Yue Liu, Aaron Colak, Anuj Kumar, Wen-tau Yih, Xin Luna Dong

**Published:** 2025-06-10 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 90.0/100

## Abstract

arXiv:2506.07309v1 Announce Type: new 
Abstract: Can we teach Large Language Models (LLMs) to refrain from hallucinating factual statements? In this paper we present a fine-tuning strategy that we call ConfQA, which can reduce hallucination rate from 20-40% to under 5% across multiple factuality benchmarks. The core idea is simple: when the LLM answers a question correctly, it is trained to continue with the answer; otherwise, it is trained to admit "I am unsure". But there are two key factors that make the training highly effective. First, we introduce a dampening prompt "answer only if you are confident" to explicitly guide the behavior, without which hallucination remains high as 15%-25%. Second, we leverage simple factual statements, specifically attribute values from knowledge graphs, to help LLMs calibrate the confidence, resulting in robust generalization across domains and question types. Building on this insight, we propose the Dual Neural Knowledge framework, which seamlessly select between internally parameterized neural knowledge and externally recorded symbolic knowledge based on ConfQA's confidence. The framework enables potential accuracy gains to beyond 95%, while reducing unnecessary external retrievals by over 30%.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 80.0/100  
**Sentiment Score:** 92.0/100

**Justification:** This paper addresses the critical problem of hallucination in LLMs, a major barrier to their reliable deployment. The ConfQA strategy, particularly the 'answer only if confident' prompt and leveraging knowledge graph attributes, appears to be a significant improvement over existing methods, achieving a substantial reduction in hallucination rates. The mention of a 'Dual Neural Knowledge framework' suggests further development and potential for broader applicability, indicating a strong likelihood of positive reception within the community.

## Keywords

knowledge, answer, confqa, answer confident, confidence, confident, factual, factual statements, framework, hallucination

## Links

- [Paper URL](https://arxiv.org/abs/2506.07309)

---
*Auto-generated on 2025-06-10 09:29:56 UTC*
