# KBQA-o1: Agentic Knowledge Base Question Answering with Monte Carlo Tree Search

**Authors:** Haoran Luo, Haihong E, Yikai Guo, Qika Lin, Xiaobao Wu, Xinyu Mu, Wenhao Liu, Meina Song, Yifan Zhu, Luu Anh Tuan

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 36.6/100

## Abstract

arXiv:2501.18922v3 Announce Type: replace 
Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural language questions with a large-scale structured knowledge base (KB). Despite advancements with large language models (LLMs), KBQA still faces challenges in weak KB awareness, imbalance between effectiveness and efficiency, and high reliance on annotated data. To address these challenges, we propose KBQA-o1, a novel agentic KBQA method with Monte Carlo Tree Search (MCTS). It introduces a ReAct-based agent process for stepwise logical form generation with KB environment exploration. Moreover, it employs MCTS, a heuristic search method driven by policy and reward models, to balance agentic exploration's performance and search space. With heuristic exploration, KBQA-o1 generates high-quality annotations for further improvement by incremental fine-tuning. Experimental results show that KBQA-o1 outperforms previous low-resource KBQA methods with limited annotated data, boosting Llama-3.1-8B model's GrailQA F1 performance to 78.5% compared to 48.5% of the previous sota method with GPT-3.5-turbo. Our code is publicly available.

## Analysis

**Innovation Score:** 20.0/100
**Impact Score:** 8.0/100  
**Sentiment Score:** 55.5/100

**Justification:** Contains key LLM terms (bonus: 15)

## Keywords

kbqa, kbqa o1, o1, search, agentic, base, exploration, kb, knowledge, knowledge base

## Links

- [Paper URL](https://arxiv.org/abs/2501.18922)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
