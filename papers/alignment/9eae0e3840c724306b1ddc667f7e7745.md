# Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models

**Authors:** Mingyu Yu, Wei Wang, Yanjie Wei, Sujuan Qin

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 44.7/100

## Abstract

arXiv:2505.23404v1 Announce Type: new 
Abstract: Adversarial attacks on Large Language Models (LLMs) via jailbreaking techniques-methods that circumvent their built-in safety and ethical constraints-have emerged as a critical challenge in AI security. These attacks compromise the reliability of LLMs by exploiting inherent weaknesses in their comprehension capabilities. This paper investigates the efficacy of jailbreaking strategies that are specifically adapted to the diverse levels of understanding exhibited by different LLMs. We propose the Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models, a novel framework that classifies LLMs into Type I and Type II categories according to their semantic comprehension abilities. For each category, we design tailored jailbreaking strategies aimed at leveraging their vulnerabilities to facilitate successful attacks. Extensive experiments conducted on multiple LLMs demonstrate that our adaptive strategy markedly improves the success rate of jailbreaking. Notably, our approach achieves an exceptional 98.9% success rate in jailbreaking GPT-4o(29 May 2025 release)

## Analysis

**Innovation Score:** 30.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 52.1/100

**Justification:** High innovation indicators (score: 30); Contains key LLM terms (bonus: 15)

## Keywords

jailbreaking, llms, jailbreaking strategies, strategies, adaptive, attacks, capabilities, language, language models, large

## Links

- [Paper URL](https://arxiv.org/abs/2505.23404)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
