# Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data

**Authors:** Seohyeong Lee, Eunwon Kim, Hwaran Lee, Buru Chang

**Published:** 2025-05-30 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 35.4/100

## Abstract

arXiv:2505.23114v1 Announce Type: new 
Abstract: Human preference data plays a critical role in aligning large language models (LLMs) with human values. However, collecting such data is often expensive and inefficient, posing a significant scalability challenge. To address this, we introduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and diagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we compute alignment scores for LLM-generated responses to instructions from existing preference datasets. These scores are then used to construct an Alignment Data Map based on their mean and variance. Our experiments show that using only 33 percent of the data, specifically samples in the high-mean, low-variance region, achieves performance comparable to or better than using the entire dataset. This finding suggests that the Alignment Data Map can significantly improve data collection efficiency by identifying high-quality samples for LLM alignment without requiring explicit annotations. Moreover, the Alignment Data Map can diagnose existing preference datasets. Our analysis shows that it effectively detects low-impact or potentially misannotated samples. Source code is available online.

## Analysis

**Innovation Score:** 10.0/100
**Impact Score:** 16.0/100  
**Sentiment Score:** 54.6/100

**Justification:** Contains key LLM terms (bonus: 15)

## Keywords

data, alignment, preference, alignment data, data map, map, llm, preference data, samples, using

## Links

- [Paper URL](https://arxiv.org/abs/2505.23114)

---
*Auto-generated on 2025-05-30 11:01:12 UTC*
