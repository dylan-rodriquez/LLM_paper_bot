# SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues

**Authors:** Martin Kuo, Jianyi Zhang, Aolin Ding, Louis DiValentin, Amin Hass, Benjamin F Morris, Isaac Jacobson, Randolph Linderman, James Kiessling, Nicolas Ramos, Bhavna Gopal, Maziyar Baran Pouyan, Changwei Liu, Hai Li, Yiran Chen

**Published:** 2025-06-03 | **Source:** arXiv RSS

**Categories:** cs.CL

**Significance Score:** 92.0/100

## Abstract

arXiv:2506.00668v1 Announce Type: new 
Abstract: Malicious attackers can exploit large language models (LLMs) by engaging them in multi-turn dialogues to achieve harmful objectives, posing significant safety risks to society. To address this challenge, we propose a novel defense mechanism: SafeTy Reasoning Elicitation Alignment for Multi-Turn Dialogues (STREAM). STREAM defends LLMs against multi-turn attacks while preserving their functional capabilities. Our approach involves constructing a human-annotated dataset, the Safety Reasoning Multi-turn Dialogues dataset, which is used to fine-tune a plug-and-play safety reasoning moderator. This model is designed to identify malicious intent hidden within multi-turn conversations and alert the target LLM of potential risks. We evaluate STREAM across multiple LLMs against prevalent multi-turn attack strategies. Experimental results demonstrate that our method significantly outperforms existing defense techniques, reducing the Attack Success Rate (ASR) by 51.2%, all while maintaining comparable LLM capability.

## Analysis

**Innovation Score:** 75.0/100
**Impact Score:** 88.0/100  
**Sentiment Score:** 85.0/100

**Justification:** This paper addresses a highly relevant and critical problem â€“ the safety of LLMs against multi-turn adversarial attacks. The proposed STREAM approach, involving a new dataset and a plug-and-play moderator, appears well-reasoned and demonstrates improved performance over existing defenses. While the core idea of a safety moderator isn't entirely novel, the focus on multi-turn dialogues and the creation of a dedicated dataset contribute to its value.

## Keywords

multi, multi turn, turn, safety, dialogues, reasoning, safety reasoning, turn dialogues, llms, stream

## Links

- [Paper URL](https://arxiv.org/abs/2506.00668)

---
*Auto-generated on 2025-06-03 09:29:41 UTC*
